<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SSD Training - Simple</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.2.0"></script>
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family:
          -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu,
          Cantarell, sans-serif;
        padding: 20px;
        background: #f5f5f5;
        color: #333;
      }

      .container {
        max-width: 1400px;
        margin: 0 auto;
        background: white;
        padding: 30px;
        border-radius: 12px;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
      }

      h1 {
        margin-bottom: 10px;
        color: #2c3e50;
      }

      .subtitle {
        color: #7f8c8d;
        margin-bottom: 30px;
      }

      .upload-section {
        margin-bottom: 30px;
        padding: 20px;
        background: #f8f9fa;
        border-radius: 8px;
      }

      button {
        background: #3498db;
        color: white;
        border: none;
        padding: 12px 24px;
        border-radius: 6px;
        cursor: pointer;
        font-size: 16px;
        margin-right: 10px;
        transition: background 0.3s;
      }

      button:hover:not(:disabled) {
        background: #2980b9;
      }

      button:disabled {
        background: #bdc3c7;
        cursor: not-allowed;
      }

      .status {
        margin-top: 15px;
        padding: 12px;
        background: #e8f4f8;
        border-left: 4px solid #3498db;
        border-radius: 4px;
      }

      .training-info {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 15px;
        margin-bottom: 30px;
      }

      .info-card {
        background: #f8f9fa;
        padding: 15px;
        border-radius: 8px;
        text-align: center;
      }

      .info-label {
        font-size: 12px;
        color: #7f8c8d;
        margin-bottom: 5px;
      }

      .info-value {
        font-size: 24px;
        font-weight: bold;
        color: #2c3e50;
      }

      .image-section {
        margin-bottom: 40px;
      }

      .image-section-header {
        font-size: 18px;
        font-weight: 600;
        color: #2c3e50;
        margin-bottom: 15px;
        padding-bottom: 8px;
        border-bottom: 2px solid #e0e0e0;
      }

      .images-grid {
        display: grid;
        grid-template-columns: repeat(5, 1fr);
        gap: 20px;
        margin-top: 10px;
      }

      .image-item {
        border: 2px solid #e0e0e0;
        border-radius: 8px;
        padding: 10px;
        background: #fafafa;
      }

      .image-item.active {
        border-color: #3498db;
        background: #e8f4f8;
      }

      .image-name {
        font-size: 12px;
        margin-bottom: 10px;
        word-wrap: break-word;
        word-break: break-all;
        overflow-wrap: break-word;
        max-width: 100%;
        line-height: 1.4;
        color: #555;
        transition:
          opacity 0.2s,
          max-height 0.2s;
      }

      .hide-image-names .image-name {
        display: none;
      }

      .image-section.hide-image-names .image-name {
        display: none;
      }

      .image-controls {
        display: flex;
        align-items: center;
        gap: 10px;
        margin-bottom: 10px;
        font-size: 12px;
      }

      .no-object-label {
        display: flex;
        align-items: center;
        gap: 5px;
        cursor: pointer;
      }

      .no-object-label input[type='checkbox'] {
        cursor: pointer;
      }

      .image-item.no-object {
        opacity: 0.7;
        border-color: #95a5a6;
      }

      .image-item.no-object .image-name::after {
        content: ' (No Object)';
        color: #e74c3c;
        font-weight: bold;
      }

      .canvas-container {
        position: relative;
        width: 100%;
        margin-bottom: 10px;
      }

      .image-canvas,
      .annotation-canvas,
      .prediction-overlay {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
      }

      .image-canvas {
        z-index: 1;
      }

      .annotation-canvas {
        z-index: 2;
        pointer-events: none;
      }

      .prediction-overlay {
        z-index: 3;
        pointer-events: none;
        visibility: visible;
        opacity: 1;
      }

      .image-section.drawing-mode .annotation-canvas {
        pointer-events: auto;
        cursor: crosshair;
      }

      .image-item.active .annotation-canvas {
        pointer-events: auto;
      }

      .log-container {
        margin-top: 20px;
        padding: 15px;
        background: #2c3e50;
        color: #ecf0f1;
        border-radius: 8px;
        max-height: 200px;
        overflow-y: auto;
        font-family: 'Courier New', monospace;
        font-size: 12px;
      }

      .log-entry {
        margin-bottom: 5px;
        padding: 3px 0;
      }

      .log-entry.success {
        color: #2ecc71;
      }

      .log-entry.error {
        color: #e74c3c;
      }

      .log-entry.info {
        color: #3498db;
      }

      .controls {
        display: flex;
        align-items: center;
        gap: 15px;
        margin-bottom: 20px;
        flex-wrap: wrap;
      }

      .controls label {
        display: flex;
        align-items: center;
        gap: 5px;
      }

      .controls input {
        padding: 4px 8px;
        border: 1px solid #ddd;
        border-radius: 4px;
        width: 80px;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>SSD Training - Simple</h1>
      <p class="subtitle">
        Load images, mark target boxes, and train on all images
      </p>

      <div class="upload-section">
        <div class="controls">
          <input
            type="file"
            id="trainingImageInput"
            accept="image/*"
            multiple
            style="display: none"
          />
          <input
            type="file"
            id="testingImageInput"
            accept="image/*"
            multiple
            style="display: none"
          />
          <button
            onclick="document.getElementById('trainingImageInput').click()"
          >
            Select Training Images
          </button>
          <button
            onclick="document.getElementById('testingImageInput').click()"
          >
            Select Testing Images
          </button>
          <button id="drawBoxBtn" disabled>Draw Target Box</button>
          <button id="startTrainingBtn" disabled>Start Training</button>
          <button id="stopTrainingBtn" disabled>Stop Training</button>
          <button id="exportAnnotationsBtn" disabled>Export Annotations</button>
          <button id="importAnnotationsBtn">Import Annotations</button>
          <input
            type="file"
            id="importAnnotationsInput"
            accept=".json"
            style="display: none"
          />
        </div>

        <div class="controls" style="margin-top: 10px">
          <label for="learningRateInput">
            Learning Rate:
            <input
              type="number"
              id="learningRateInput"
              min="1e-6"
              max="1e-2"
              step="1e-5"
              value="0.0001"
            />
          </label>
          <label for="showImageNamesToggle" style="margin-left: 15px">
            <input type="checkbox" id="showImageNamesToggle" />
            Show Image Names
          </label>
          <label for="numColumnsInput" style="margin-left: 15px">
            Columns:
            <input
              type="number"
              id="numColumnsInput"
              min="1"
              max="10"
              step="1"
              value="5"
              style="width: 50px"
            />
          </label>
        </div>

        <div class="status" id="statusDiv">Ready to load images</div>
      </div>

      <div class="training-info">
        <div class="info-card">
          <div class="info-label">Epoch</div>
          <div class="info-value" id="epochValue">0</div>
        </div>
        <div class="info-card">
          <div class="info-label">Train Total Loss</div>
          <div class="info-value" id="trainTotalLossValue">-</div>
        </div>
        <div class="info-card">
          <div class="info-label">Train Box Loss</div>
          <div class="info-value" id="trainBoxLossValue">-</div>
        </div>
        <div class="info-card">
          <div class="info-label">Train Class Loss</div>
          <div class="info-value" id="trainClassLossValue">-</div>
        </div>
        <div class="info-card">
          <div class="info-label">Test Total Loss</div>
          <div class="info-value" id="testTotalLossValue">-</div>
        </div>
        <div class="info-card">
          <div class="info-label">Test Box Loss</div>
          <div class="info-value" id="testBoxLossValue">-</div>
        </div>
        <div class="info-card">
          <div class="info-label">Test Class Loss</div>
          <div class="info-value" id="testClassLossValue">-</div>
        </div>
      </div>

      <div class="image-section" id="trainingSection">
        <div class="image-section-header">Training Images</div>
        <div class="images-grid" id="trainingImagesGrid"></div>
      </div>

      <div class="image-section" id="testingSection">
        <div class="image-section-header">Testing Images</div>
        <div class="images-grid" id="testingImagesGrid"></div>
      </div>

      <div class="log-container" id="logContainer"></div>
    </div>

    <script>
      // Constants
      const IMAGE_SIZE = 224
      const NUM_CLASSES = 2 // background + 1 object class
      let currentLearningRate = 1e-4

      // UI elements
      const trainingImageInput = document.getElementById('trainingImageInput')
      const testingImageInput = document.getElementById('testingImageInput')
      const startBtn = document.getElementById('startTrainingBtn')
      const stopBtn = document.getElementById('stopTrainingBtn')
      const drawBoxBtn = document.getElementById('drawBoxBtn')
      const learningRateInput = document.getElementById('learningRateInput')
      const statusDiv = document.getElementById('statusDiv')
      const trainingImagesGrid = document.getElementById('trainingImagesGrid')
      const testingImagesGrid = document.getElementById('testingImagesGrid')
      const trainingSection = document.getElementById('trainingSection')
      const testingSection = document.getElementById('testingSection')
      const logContainer = document.getElementById('logContainer')

      // State
      let featureExtractor = null
      let detectionModel = null
      let isTraining = false
      let currentEpoch = 0
      let trainingDataset = []
      let testingDataset = []
      let isDrawingMode = false
      let isDrawing = false
      let drawStartX = 0
      let drawStartY = 0
      let currentDrawingImageIndex = -1

      // Logging utility
      function log(message, type = 'info') {
        const entry = document.createElement('div')
        entry.className = `log-entry ${type}`
        entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`
        logContainer.appendChild(entry)
        logContainer.scrollTop = logContainer.scrollHeight
        console.log(`[${type.toUpperCase()}]`, message)
      }

      // LocalStorage utilities
      // Box format: [centerX, centerY, width, height] (normalized 0-1)
      // 0 represents "no object" in localStorage
      function getStorageKey(fileName) {
        return `box_${fileName}`
      }

      function saveTargetBox(fileName, box) {
        const key = getStorageKey(fileName)
        // Store as JSON: [x, y, w, h] where x, y are center coordinates
        // 0 for no object
        if (
          box === false ||
          (Array.isArray(box) &&
            box[0] === 0 &&
            box[1] === 0 &&
            box[2] === 0 &&
            box[3] === 0)
        ) {
          localStorage.setItem(key, JSON.stringify(0))
        } else if (Array.isArray(box) && box.length === 4) {
          localStorage.setItem(key, JSON.stringify(box))
        }
      }

      function loadTargetBox(fileName) {
        const key = getStorageKey(fileName)
        const data = localStorage.getItem(key)
        if (data) {
          try {
            const parsed = JSON.parse(data)
            // Handle 0 as no object
            if (parsed === 0) {
              return [0, 0, 0, 0] // Return array for compatibility with code
            }
            // Handle legacy format with object
            if (
              parsed &&
              typeof parsed === 'object' &&
              !Array.isArray(parsed)
            ) {
              return [
                parsed.centerX,
                parsed.centerY,
                parsed.width,
                parsed.height,
              ]
            }
            if (Array.isArray(parsed) && parsed.length === 4) {
              return parsed
            }
          } catch (e) {
            // Handle legacy format or invalid data
            return null
          }
        }
        return null
      }

      function getNoObjectKey(fileName) {
        return `box_${fileName}`
      }

      function saveNoObjectFlag(fileName, isNoObject) {
        const key = getNoObjectKey(fileName)
        if (isNoObject) {
          localStorage.setItem(key, JSON.stringify(0))
        } else {
          // If setting to false, remove the 0 entry
          const existing = loadTargetBox(fileName)
          if (
            existing &&
            existing[0] === 0 &&
            existing[1] === 0 &&
            existing[2] === 0 &&
            existing[3] === 0
          ) {
            localStorage.removeItem(key)
          }
        }
      }

      function loadNoObjectFlag(fileName) {
        const key = getStorageKey(fileName)
        const data = localStorage.getItem(key)
        if (data) {
          try {
            const parsed = JSON.parse(data)
            return parsed === 0
          } catch (e) {
            // Handle legacy format
            const box = loadTargetBox(fileName)
            return (
              box &&
              box[0] === 0 &&
              box[1] === 0 &&
              box[2] === 0 &&
              box[3] === 0
            )
          }
        }
        return false
      }

      // Export annotations to JSON
      // Format: [filename, [x, y, w, h]] where x, y are center coordinates
      // [filename, 0] for no object
      function exportAnnotations() {
        const exportData = {
          training: [],
          testing: [],
          version: '1.0',
          exportDate: new Date().toISOString(),
        }

        // Export training images
        trainingDataset.forEach(imgData => {
          const box = loadTargetBox(imgData.name)
          const isNoObject = loadNoObjectFlag(imgData.name)
          // Format: [filename, [x, y, w, h]] or [filename, 0] for no object
          if (
            isNoObject ||
            (box &&
              box[0] === 0 &&
              box[1] === 0 &&
              box[2] === 0 &&
              box[3] === 0)
          ) {
            exportData.training.push([imgData.name, 0])
          } else {
            exportData.training.push([
              imgData.name,
              box || [0.5, 0.5, 0.5, 0.5],
            ])
          }
        })

        // Export testing images
        testingDataset.forEach(imgData => {
          const box = loadTargetBox(imgData.name)
          const isNoObject = loadNoObjectFlag(imgData.name)
          // Format: [filename, [x, y, w, h]] or [filename, 0] for no object
          if (
            isNoObject ||
            (box &&
              box[0] === 0 &&
              box[1] === 0 &&
              box[2] === 0 &&
              box[3] === 0)
          ) {
            exportData.testing.push([imgData.name, 0])
          } else {
            exportData.testing.push([imgData.name, box || [0.5, 0.5, 0.5, 0.5]])
          }
        })

        // Create download link
        const jsonStr = JSON.stringify(exportData, null, 2)
        const blob = new Blob([jsonStr], { type: 'application/json' })
        const url = URL.createObjectURL(blob)
        const a = document.createElement('a')
        a.href = url
        a.download = `annotations_${new Date().toISOString().split('T')[0]}.json`
        document.body.appendChild(a)
        a.click()
        document.body.removeChild(a)
        URL.revokeObjectURL(url)

        log(
          `Exported ${exportData.training.length} training and ${exportData.testing.length} testing annotations`,
          'success',
        )
      }

      // Import annotations from JSON
      async function importAnnotations(file) {
        return new Promise((resolve, reject) => {
          const reader = new FileReader()
          reader.onload = e => {
            try {
              const importData = JSON.parse(e.target.result)

              if (!importData.training && !importData.testing) {
                throw new Error(
                  'Invalid JSON format: missing "training" or "testing" arrays',
                )
              }

              let importedCount = 0

              // Import training annotations
              // Format: [filename, [x, y, w, h]] or [filename, 0] for no object
              if (importData.training && Array.isArray(importData.training)) {
                importData.training.forEach(item => {
                  // Handle new array format: [filename, box]
                  if (Array.isArray(item) && item.length === 2) {
                    const filename = item[0]
                    const box = item[1]
                    if (box === 0 || box === false) {
                      // No object: save as [0, 0, 0, 0]
                      saveTargetBox(filename, [0, 0, 0, 0])
                    } else if (Array.isArray(box) && box.length === 4) {
                      // Has box: save box array
                      saveTargetBox(filename, box)
                    }
                    importedCount++
                  } else if (item.filename && item.hasOwnProperty('box')) {
                    // Handle legacy object format: {filename: ..., box: ...}
                    if (item.box === false || item.box === 0) {
                      saveTargetBox(item.filename, [0, 0, 0, 0])
                    } else if (
                      Array.isArray(item.box) &&
                      item.box.length === 4
                    ) {
                      saveTargetBox(item.filename, item.box)
                    }
                    importedCount++
                  }
                })
              }

              // Import testing annotations
              // Format: [filename, [x, y, w, h]] or [filename, 0] for no object
              if (importData.testing && Array.isArray(importData.testing)) {
                importData.testing.forEach(item => {
                  // Handle new array format: [filename, box]
                  if (Array.isArray(item) && item.length === 2) {
                    const filename = item[0]
                    const box = item[1]
                    if (box === 0 || box === false) {
                      // No object: save as [0, 0, 0, 0]
                      saveTargetBox(filename, [0, 0, 0, 0])
                    } else if (Array.isArray(box) && box.length === 4) {
                      // Has box: save box array
                      saveTargetBox(filename, box)
                    }
                    importedCount++
                  } else if (item.filename && item.hasOwnProperty('box')) {
                    // Handle legacy object format: {filename: ..., box: ...}
                    if (item.box === false || item.box === 0) {
                      saveTargetBox(item.filename, [0, 0, 0, 0])
                    } else if (
                      Array.isArray(item.box) &&
                      item.box.length === 4
                    ) {
                      saveTargetBox(item.filename, item.box)
                    }
                    importedCount++
                  }
                })
              }

              log(
                `Imported ${importedCount} annotation(s) from JSON`,
                'success',
              )

              // Reload annotations for currently loaded images
              if (trainingDataset.length > 0 || testingDataset.length > 0) {
                // Reload boxes and flags for all images
                trainingDataset.forEach(imgData => {
                  const box = loadTargetBox(imgData.name)
                  if (box) {
                    imgData.box.dispose()
                    imgData.box = tf.tensor2d([box], [1, 4])
                  }
                  const isNoObject = loadNoObjectFlag(imgData.name)
                  imgData.isNoObject = isNoObject
                  imgData.class.dispose()
                  imgData.class = isNoObject
                    ? tf.tensor2d([[1, 0]], [1, NUM_CLASSES])
                    : tf.tensor2d([[0, 1]], [1, NUM_CLASSES])
                })

                testingDataset.forEach(imgData => {
                  const box = loadTargetBox(imgData.name)
                  if (box) {
                    imgData.box.dispose()
                    imgData.box = tf.tensor2d([box], [1, 4])
                  }
                  const isNoObject = loadNoObjectFlag(imgData.name)
                  imgData.isNoObject = isNoObject
                  imgData.class.dispose()
                  imgData.class = isNoObject
                    ? tf.tensor2d([[1, 0]], [1, NUM_CLASSES])
                    : tf.tensor2d([[0, 1]], [1, NUM_CLASSES])
                })

                // Redraw all images
                displayAllImages()

                // Update predictions if model is ready
                if (detectionModel) {
                  visualizePredictions()
                }
              }

              resolve(importedCount)
            } catch (error) {
              log(`Error importing annotations: ${error.message}`, 'error')
              reject(error)
            }
          }
          reader.onerror = reject
          reader.readAsText(file)
        })
      }

      // Initialize: Load MobileNet feature extractor
      async function initializeModel() {
        log('Loading MobileNet feature extractor...', 'info')
        statusDiv.textContent = 'Loading MobileNet...'

        try {
          const modelUrl =
            '/saved_models/mobilenet-v3-tfjs-large-100-224-feature-vector-v1/model.json'

          log(`Loading from: ${modelUrl}`, 'info')
          const mobilenetGraph = await tf.loadGraphModel(modelUrl)

          featureExtractor = mobilenetGraph

          log('MobileNet loaded successfully', 'success')
          statusDiv.textContent =
            'MobileNet loaded. Building detection model...'
          buildDetectionModel()
        } catch (error) {
          log(`Error loading model: ${error.message}`, 'error')
          statusDiv.textContent = `Error: ${error.message}`
        }
      }

      // Build SSD detection head
      function buildDetectionModel() {
        log('Building detection model...', 'info')

        const featureInput = tf.input({ shape: [1280] })

        // Shared intermediate layer with proper weight initialization
        const shared = tf.layers
          .dense({
            units: 256,
            activation: 'relu',
            name: 'shared_layer',
            kernelInitializer: 'glorotUniform',
            biasInitializer: 'zeros',
          })
          .apply(featureInput)

        // Bounding box head
        const boxIntermediate = tf.layers
          .dense({
            units: 128,
            activation: 'relu',
            name: 'box_intermediate',
            kernelInitializer: 'glorotUniform',
            biasInitializer: 'zeros',
          })
          .apply(shared)

        const boxHead = tf.layers
          .dense({
            units: 4,
            activation: 'sigmoid',
            name: 'box_head',
            kernelInitializer: 'glorotUniform',
            biasInitializer: 'zeros',
          })
          .apply(boxIntermediate)

        // Classification head
        const classIntermediate = tf.layers
          .dense({
            units: 128,
            activation: 'relu',
            name: 'class_intermediate',
            kernelInitializer: 'glorotUniform',
            biasInitializer: 'zeros',
          })
          .apply(shared)

        const classHead = tf.layers
          .dense({
            units: NUM_CLASSES,
            activation: null, // No activation - output logits for softmaxCrossEntropy
            name: 'class_head',
            kernelInitializer: 'glorotUniform',
            biasInitializer: 'zeros',
          })
          .apply(classIntermediate)

        detectionModel = tf.model({
          inputs: featureInput,
          outputs: [boxHead, classHead],
        })

        // Compile model
        updateModelLearningRate(currentLearningRate)

        log('Detection model built and compiled', 'success')
        log(`Model summary: ${detectionModel.countParams()} parameters`, 'info')

        // Update status immediately after model is built
        if (trainingDataset.length > 0 || testingDataset.length > 0) {
          statusDiv.textContent = `Model ready. ${trainingDataset.length} training, ${testingDataset.length} testing image(s) loaded.`
        } else {
          statusDiv.textContent = 'Model ready. Load images to start training.'
        }

        // Show predictions if images are already loaded (async, but status is already updated)
        if (trainingDataset.length > 0 || testingDataset.length > 0) {
          visualizePredictions().catch(err => {
            log(`Error visualizing predictions: ${err.message}`, 'error')
          })
        }
      }

      // Update model learning rate
      function updateModelLearningRate(lr) {
        if (!detectionModel) return
        currentLearningRate = lr
        // Use Adam optimizer with gradient clipping to prevent NaN
        const optimizer = tf.train.adam(lr)
        detectionModel.compile({
          optimizer: optimizer,
          loss: ['meanSquaredError', 'categoricalCrossentropy'],
          lossWeights: [1.0, 0.5],
          metrics: ['accuracy'],
        })
      }

      // Load image into dataset
      async function loadImageIntoDataset(file, index, dataset) {
        return new Promise((resolve, reject) => {
          const reader = new FileReader()
          reader.onload = async e => {
            try {
              const img = new Image()
              img.onload = async () => {
                // Create canvas and resize
                const canvas = document.createElement('canvas')
                canvas.width = IMAGE_SIZE
                canvas.height = IMAGE_SIZE
                const ctx = canvas.getContext('2d')
                ctx.drawImage(img, 0, 0, IMAGE_SIZE, IMAGE_SIZE)

                // Convert to tensor and normalize to [-1, 1]
                const imageData = ctx.getImageData(0, 0, IMAGE_SIZE, IMAGE_SIZE)
                const tensor = tf.browser
                  .fromPixels(imageData)
                  .toFloat()
                  .div(127.5)
                  .sub(1.0)
                  .expandDims(0)

                // Load or create default target box
                let box = loadTargetBox(file.name)
                if (!box) {
                  // Default: center box covering 50% of image
                  box = [0.5, 0.5, 0.5, 0.5]
                }
                const boxTensor = tf.tensor2d([box], [1, 4])

                // Check if marked as "no object"
                const isNoObject = loadNoObjectFlag(file.name)
                // Class: [background=0, object=1] or [background=1, object=0] if no object
                const classTensor = isNoObject
                  ? tf.tensor2d([[1, 0]], [1, NUM_CLASSES])
                  : tf.tensor2d([[0, 1]], [1, NUM_CLASSES])

                const imgData = {
                  file: file,
                  name: file.name,
                  element: img,
                  tensor: tensor,
                  box: boxTensor,
                  class: classTensor,
                  boxLoss: null,
                  totalLoss: null,
                  isNoObject: isNoObject,
                  features: null, // Cached MobileNet features
                }

                dataset[index] = imgData
                resolve(imgData)
              }
              img.src = e.target.result
            } catch (error) {
              reject(error)
            }
          }
          reader.onerror = reject
          reader.readAsDataURL(file)
        })
      }

      // Load training images
      async function loadTrainingImages() {
        const files = Array.from(trainingImageInput.files)
        if (files.length === 0) return

        log(`Loading ${files.length} training image(s)...`, 'info')
        statusDiv.textContent = `Loading ${files.length} training image(s)...`

        // Clear any cached features from previous training images
        clearCachedFeatures(trainingDataset)

        // Clear training dataset
        trainingDataset = []

        // Load and display training images one by one
        for (let i = 0; i < files.length; i++) {
          statusDiv.textContent = `Loading training image ${i + 1}/${files.length}: ${files[i].name}...`
          log(
            `Loading training image ${i + 1}/${files.length}: ${files[i].name}`,
            'info',
          )

          await loadImageIntoDataset(files[i], i, trainingDataset)

          // Display the image immediately for visual feedback
          displaySingleImage(i, trainingDataset, 'training')

          // Show prediction for this image if model is ready (one by one)
          if (detectionModel) {
            await visualizePredictionForImage(i, trainingDataset)
          }

          // Small delay to allow UI to update
          await new Promise(resolve => setTimeout(resolve, 10))
        }

        log(`Loaded ${trainingDataset.length} training image(s)`, 'success')
        updateUIState()
        displayAllImages()

        // Re-show predictions after displayAllImages (since it clears and redraws)
        if (detectionModel) {
          await visualizePredictions()
        }
      }

      // Load testing images
      async function loadTestingImages() {
        const files = Array.from(testingImageInput.files)
        if (files.length === 0) return

        log(`Loading ${files.length} testing image(s)...`, 'info')
        statusDiv.textContent = `Loading ${files.length} testing image(s)...`

        // Clear any cached features from previous testing images
        clearCachedFeatures(testingDataset)

        // Clear testing dataset
        testingDataset = []

        // Load and display testing images one by one
        for (let i = 0; i < files.length; i++) {
          statusDiv.textContent = `Loading testing image ${i + 1}/${files.length}: ${files[i].name}...`
          log(
            `Loading testing image ${i + 1}/${files.length}: ${files[i].name}`,
            'info',
          )

          await loadImageIntoDataset(files[i], i, testingDataset)

          // Display the image immediately for visual feedback
          displaySingleImage(i, testingDataset, 'testing')

          // Show prediction for this image if model is ready (one by one)
          if (detectionModel) {
            await visualizePredictionForImage(i, testingDataset)
          }

          // Small delay to allow UI to update
          await new Promise(resolve => setTimeout(resolve, 10))
        }

        log(`Loaded ${testingDataset.length} testing image(s)`, 'success')
        updateUIState()
        displayAllImages()

        // Re-show predictions after displayAllImages (since it clears and redraws)
        if (detectionModel) {
          await visualizePredictions()
        }
      }

      // Update UI state based on datasets
      function updateUIState() {
        const hasImages =
          trainingDataset.length > 0 || testingDataset.length > 0
        drawBoxBtn.disabled = !hasImages
        startBtn.disabled = trainingDataset.length === 0
        const exportBtn = document.getElementById('exportAnnotationsBtn')
        if (exportBtn) {
          exportBtn.disabled = !hasImages
        }

        const totalImages = trainingDataset.length + testingDataset.length
        if (totalImages > 0) {
          // Only update status if model is ready (to avoid overwriting "Building detection model..." message)
          if (detectionModel) {
            statusDiv.textContent = `Loaded ${trainingDataset.length} training, ${testingDataset.length} testing image(s). Mark target boxes and start training.`
          }
        } else if (detectionModel) {
          // Model is ready but no images loaded
          statusDiv.textContent = 'Model ready. Load images to start training.'
        }
      }

      // Display a single image in the grid
      function displaySingleImage(index, dataset, datasetType = 'training') {
        if (index < 0 || index >= dataset.length) return

        const imgData = dataset[index]

        const item = document.createElement('div')
        item.className = 'image-item'
        item.id = `image-item-${datasetType}-${index}`
        item.dataset.type = datasetType

        const nameDiv = document.createElement('div')
        nameDiv.className = 'image-name'
        nameDiv.textContent = `[${datasetType.toUpperCase()}] ${imgData.name}`

        // Controls for marking as "no object"
        const controlsDiv = document.createElement('div')
        controlsDiv.className = 'image-controls'

        const noObjectLabel = document.createElement('label')
        noObjectLabel.className = 'no-object-label'

        const noObjectCheckbox = document.createElement('input')
        noObjectCheckbox.type = 'checkbox'
        noObjectCheckbox.checked = imgData.isNoObject || false
        noObjectCheckbox.addEventListener('change', () => {
          const isNoObject = noObjectCheckbox.checked
          imgData.isNoObject = isNoObject
          saveNoObjectFlag(imgData.name, isNoObject)

          // Update class tensor
          imgData.class.dispose()
          imgData.class = isNoObject
            ? tf.tensor2d([[1, 0]], [1, NUM_CLASSES])
            : tf.tensor2d([[0, 1]], [1, NUM_CLASSES])

          // Update UI
          if (isNoObject) {
            item.classList.add('no-object')
          } else {
            item.classList.remove('no-object')
          }

          // Update predictions
          if (detectionModel) {
            visualizePredictions()
          }
        })

        noObjectLabel.appendChild(noObjectCheckbox)
        noObjectLabel.appendChild(document.createTextNode('No Object'))

        controlsDiv.appendChild(noObjectLabel)

        // Apply "no object" styling if needed
        if (imgData.isNoObject) {
          item.classList.add('no-object')
        }

        const container = document.createElement('div')
        container.className = 'canvas-container'
        container.style.position = 'relative'
        container.style.width = '100%'
        container.style.paddingBottom = '100%' // Square aspect ratio

        // Use a fixed size for canvas (will scale to container)
        const canvasSize = 300

        // Image canvas
        const imgCanvas = document.createElement('canvas')
        imgCanvas.className = 'image-canvas'
        imgCanvas.width = canvasSize
        imgCanvas.height = canvasSize
        imgCanvas.style.width = '100%'
        imgCanvas.style.height = '100%'
        const imgCtx = imgCanvas.getContext('2d')

        // Draw image scaled to canvas
        imgCtx.drawImage(imgData.element, 0, 0, canvasSize, canvasSize)

        // Annotation canvas
        const annotCanvas = document.createElement('canvas')
        annotCanvas.className = 'annotation-canvas'
        annotCanvas.width = canvasSize
        annotCanvas.height = canvasSize
        annotCanvas.style.width = '100%'
        annotCanvas.style.height = '100%'

        // Prediction canvas
        const predCanvas = document.createElement('canvas')
        predCanvas.className = 'prediction-overlay'
        predCanvas.width = canvasSize
        predCanvas.height = canvasSize
        predCanvas.style.width = '100%'
        predCanvas.style.height = '100%'

        container.appendChild(imgCanvas)
        container.appendChild(annotCanvas)
        container.appendChild(predCanvas)

        item.appendChild(nameDiv)
        item.appendChild(controlsDiv)
        item.appendChild(container)

        // Append to the correct grid based on dataset type
        const targetGrid =
          datasetType === 'training' ? trainingImagesGrid : testingImagesGrid
        targetGrid.appendChild(item)

        // Store canvas references
        imgData.canvasElements = {
          imageCanvas: imgCanvas,
          annotCanvas: annotCanvas,
          predCanvas: predCanvas,
          container: container,
        }

        // Draw target box
        drawTargetBoxForImage(index, dataset)

        // Helper function to get coordinates from mouse or touch events
        function getEventCoordinates(e) {
          const rect = annotCanvas.getBoundingClientRect()
          const scaleX = annotCanvas.width / rect.width
          const scaleY = annotCanvas.height / rect.height
          let clientX, clientY

          if (e.touches && e.touches.length > 0) {
            // Touch event
            clientX = e.touches[0].clientX
            clientY = e.touches[0].clientY
          } else if (e.changedTouches && e.changedTouches.length > 0) {
            // Touch end/cancel event
            clientX = e.changedTouches[0].clientX
            clientY = e.changedTouches[0].clientY
          } else {
            // Mouse event
            clientX = e.clientX
            clientY = e.clientY
          }

          return {
            x: (clientX - rect.left) * scaleX,
            y: (clientY - rect.top) * scaleY,
          }
        }

        // Drawing event listeners - Mouse events
        annotCanvas.addEventListener('mousedown', e => {
          if (!isDrawingMode) return
          e.preventDefault()
          isDrawing = true
          currentDrawingImageIndex = index
          item.classList.add('active')
          const coords = getEventCoordinates(e)
          drawStartX = coords.x
          drawStartY = coords.y
        })

        annotCanvas.addEventListener('mousemove', e => {
          if (!isDrawing || currentDrawingImageIndex !== index) return
          e.preventDefault()
          const coords = getEventCoordinates(e)
          const currentX = coords.x
          const currentY = coords.y

          const annotCtx = annotCanvas.getContext('2d')
          annotCtx.clearRect(0, 0, annotCanvas.width, annotCanvas.height)
          drawTargetBoxForImage(index, dataset)

          const x1 = Math.min(drawStartX, currentX)
          const y1 = Math.min(drawStartY, currentY)
          const width = Math.abs(currentX - drawStartX)
          const height = Math.abs(currentY - drawStartY)

          annotCtx.strokeStyle = '#3498db'
          annotCtx.lineWidth = 2
          annotCtx.setLineDash([5, 5])
          annotCtx.strokeRect(x1, y1, width, height)
          annotCtx.setLineDash([])
        })

        annotCanvas.addEventListener('mouseup', e => {
          if (!isDrawing || currentDrawingImageIndex !== index) return
          e.preventDefault()
          isDrawing = false

          const coords = getEventCoordinates(e)
          const endX = coords.x
          const endY = coords.y

          const x1 = Math.min(drawStartX, endX) / canvasSize
          const y1 = Math.min(drawStartY, endY) / canvasSize
          const x2 = Math.max(drawStartX, endX) / canvasSize
          const y2 = Math.max(drawStartY, endY) / canvasSize

          const centerX = (x1 + x2) / 2
          const centerY = (y1 + y2) / 2
          const width = x2 - x1
          const height = y2 - y1

          updateTargetBox(index, centerX, centerY, width, height, dataset)
          item.classList.remove('active')
          currentDrawingImageIndex = -1

          // Update prediction after drawing new box
          if (detectionModel) {
            visualizePredictions()
          }
        })

        annotCanvas.addEventListener('mouseleave', () => {
          if (isDrawing && currentDrawingImageIndex === index) {
            isDrawing = false
            item.classList.remove('active')
            currentDrawingImageIndex = -1
          }
        })

        // Drawing event listeners - Touch events (for iPad/mobile)
        annotCanvas.addEventListener(
          'touchstart',
          e => {
            if (!isDrawingMode) return
            e.preventDefault()
            isDrawing = true
            currentDrawingImageIndex = index
            item.classList.add('active')
            const coords = getEventCoordinates(e)
            drawStartX = coords.x
            drawStartY = coords.y
          },
          { passive: false },
        )

        annotCanvas.addEventListener(
          'touchmove',
          e => {
            if (!isDrawing || currentDrawingImageIndex !== index) return
            e.preventDefault()
            const coords = getEventCoordinates(e)
            const currentX = coords.x
            const currentY = coords.y

            const annotCtx = annotCanvas.getContext('2d')
            annotCtx.clearRect(0, 0, annotCanvas.width, annotCanvas.height)
            drawTargetBoxForImage(index, dataset)

            const x1 = Math.min(drawStartX, currentX)
            const y1 = Math.min(drawStartY, currentY)
            const width = Math.abs(currentX - drawStartX)
            const height = Math.abs(currentY - drawStartY)

            annotCtx.strokeStyle = '#3498db'
            annotCtx.lineWidth = 2
            annotCtx.setLineDash([5, 5])
            annotCtx.strokeRect(x1, y1, width, height)
            annotCtx.setLineDash([])
          },
          { passive: false },
        )

        annotCanvas.addEventListener(
          'touchend',
          e => {
            if (!isDrawing || currentDrawingImageIndex !== index) return
            e.preventDefault()
            isDrawing = false

            const coords = getEventCoordinates(e)
            const endX = coords.x
            const endY = coords.y

            const x1 = Math.min(drawStartX, endX) / canvasSize
            const y1 = Math.min(drawStartY, endY) / canvasSize
            const x2 = Math.max(drawStartX, endX) / canvasSize
            const y2 = Math.max(drawStartY, endY) / canvasSize

            const centerX = (x1 + x2) / 2
            const centerY = (y1 + y2) / 2
            const width = x2 - x1
            const height = y2 - y1

            updateTargetBox(index, centerX, centerY, width, height, dataset)
            item.classList.remove('active')
            currentDrawingImageIndex = -1

            // Update prediction after drawing new box
            if (detectionModel) {
              visualizePredictions()
            }
          },
          { passive: false },
        )

        annotCanvas.addEventListener(
          'touchcancel',
          e => {
            if (isDrawing && currentDrawingImageIndex === index) {
              e.preventDefault()
              isDrawing = false
              item.classList.remove('active')
              currentDrawingImageIndex = -1
            }
          },
          { passive: false },
        )
      }

      // Display all images in grid
      function displayAllImages() {
        trainingImagesGrid.innerHTML = ''
        testingImagesGrid.innerHTML = ''

        // Display training images
        trainingDataset.forEach((imgData, index) => {
          displaySingleImage(index, trainingDataset, 'training')
        })

        // Display testing images
        testingDataset.forEach((imgData, index) => {
          displaySingleImage(index, testingDataset, 'testing')
        })

        // Show/hide sections based on whether they have images
        trainingSection.style.display =
          trainingDataset.length > 0 ? 'block' : 'none'
        testingSection.style.display =
          testingDataset.length > 0 ? 'block' : 'none'
      }

      // Update target box for an image
      function updateTargetBox(
        index,
        centerX,
        centerY,
        width,
        height,
        dataset,
      ) {
        if (!dataset || index < 0 || index >= dataset.length) return

        const imgData = dataset[index]
        imgData.box.dispose()
        imgData.box = tf.tensor2d([[centerX, centerY, width, height]], [1, 4])

        saveTargetBox(imgData.name, [centerX, centerY, width, height])
        drawTargetBoxForImage(index, dataset)
        log(`Updated target box for ${imgData.name}`, 'info')
      }

      // Draw target box on annotation canvas
      function drawTargetBoxForImage(index, dataset) {
        if (!dataset || index < 0 || index >= dataset.length) return

        const imgData = dataset[index]
        if (!imgData.canvasElements) return

        const { annotCanvas, imageCanvas } = imgData.canvasElements
        const annotCtx = annotCanvas.getContext('2d')

        annotCtx.clearRect(0, 0, annotCanvas.width, annotCanvas.height)

        imgData.box.array().then(data => {
          const box = data[0]
          const centerX = box[0] * imageCanvas.width
          const centerY = box[1] * imageCanvas.height
          const width = box[2] * imageCanvas.width
          const height = box[3] * imageCanvas.height
          const x1 = centerX - width / 2
          const y1 = centerY - height / 2

          annotCtx.strokeStyle = '#2ecc71'
          annotCtx.lineWidth = 3
          annotCtx.setLineDash([5, 5])
          annotCtx.strokeRect(x1, y1, width, height)
          annotCtx.setLineDash([])

          annotCtx.fillStyle = '#2ecc71'
          annotCtx.fillRect(x1, y1 - 25, 150, 25)
          annotCtx.fillStyle = 'white'
          annotCtx.font = '14px Arial'
          annotCtx.fillText('Target Box', x1 + 5, y1 - 8)
        })
      }

      // Visualize prediction for a single image
      async function visualizePredictionForImage(index, dataset) {
        if (!detectionModel || !dataset || index < 0 || index >= dataset.length)
          return

        const imgData = dataset[index]
        if (!imgData.canvasElements) return

        const { predCanvas, imageCanvas } = imgData.canvasElements
        const predCtx = predCanvas.getContext('2d')

        const isGraphModel = featureExtractor && 'execute' in featureExtractor

        try {
          let features
          // Use cached features if available, otherwise extract on the fly
          if (imgData.features) {
            features = imgData.features.clone()
          } else {
            if (isGraphModel) {
              features = featureExtractor.execute(
                { 'inputs:0': imgData.tensor },
                'Identity:0',
              )
            } else {
              features = featureExtractor.predict(imgData.tensor)
            }
          }

          const [boxPred, classPredLogits] = detectionModel.predict(features)

          // Apply softmax to logits to get probabilities
          const classPred = classPredLogits.softmax()

          // Get values - use .data() for better performance
          const boxData = await boxPred.data()
          const classData = await classPred.data()

          // Check for NaN or invalid values
          if (
            isNaN(boxData[0]) ||
            isNaN(boxData[1]) ||
            isNaN(boxData[2]) ||
            isNaN(boxData[3]) ||
            isNaN(classData[0]) ||
            isNaN(classData[1]) ||
            !isFinite(boxData[0]) ||
            !isFinite(boxData[1]) ||
            !isFinite(boxData[2]) ||
            !isFinite(boxData[3])
          ) {
            // Clear canvas on error
            predCtx.clearRect(0, 0, predCanvas.width, predCanvas.height)
            console.warn(`NaN detected in prediction for image ${index}:`, {
              box: [boxData[0], boxData[1], boxData[2], boxData[3]],
              class: [classData[0], classData[1]],
            })
            boxPred.dispose()
            classPred.dispose()
            classPredLogits.dispose()
            features.dispose()
            return
          }

          // Clamp box values to valid range [0, 1] to prevent drawing outside canvas
          const clampedBox = [
            Math.max(0, Math.min(1, boxData[0])),
            Math.max(0, Math.min(1, boxData[1])),
            Math.max(0, Math.min(1, boxData[2])),
            Math.max(0, Math.min(1, boxData[3])),
          ]

          // Box format: [centerX, centerY, width, height] in normalized [0,1]
          // Use imageCanvas dimensions for scaling (actual rendered size)
          const centerX = clampedBox[0] * imageCanvas.width
          const centerY = clampedBox[1] * imageCanvas.height
          const w = clampedBox[2] * imageCanvas.width
          const h = clampedBox[3] * imageCanvas.height

          // Convert center coordinates to top-left
          const x1 = centerX - w / 2
          const y1 = centerY - h / 2

          // Clear the canvas first to remove old predictions
          predCtx.clearRect(0, 0, predCanvas.width, predCanvas.height)

          // Draw predicted box with red color (solid line to distinguish from target)
          predCtx.strokeStyle = '#e74c3c'
          predCtx.lineWidth = 3
          predCtx.setLineDash([]) // Solid line for predictions
          predCtx.strokeRect(x1, y1, w, h)

          // Draw label background
          const confidence = classData[1] // Object class probability (index 1)
          const labelWidth = 140
          predCtx.fillStyle = '#e74c3c'
          predCtx.fillRect(x1, y1 - 20, labelWidth, 20)

          // Draw label text
          predCtx.fillStyle = 'white'
          predCtx.font = 'bold 12px Arial'
          predCtx.fillText(
            `Predicted: ${(confidence * 100).toFixed(1)}%`,
            x1 + 5,
            y1 - 5,
          )

          // Force canvas update
          predCanvas.style.display = 'none'
          predCanvas.offsetHeight // Trigger reflow
          predCanvas.style.display = ''

          boxPred.dispose()
          classPred.dispose()
          classPredLogits.dispose()
          // Always dispose features (either clone of cached or newly extracted)
          // The cached features in imgData.features remain untouched
          features.dispose()
        } catch (error) {
          console.error(`Error visualizing for image ${index}:`, error)
          // Only clear on error, otherwise keep old prediction
          predCtx.clearRect(0, 0, predCanvas.width, predCanvas.height)
          // Draw error indicator
          predCtx.fillStyle = '#e74c3c'
          predCtx.font = '12px Arial'
          predCtx.fillText('Prediction Error', 10, 20)
        }
      }

      // Visualize predictions on all images
      async function visualizePredictions() {
        if (!detectionModel) {
          console.warn('visualizePredictions: detectionModel is not available')
          return
        }

        try {
          // Visualize training images
          for (let i = 0; i < trainingDataset.length; i++) {
            try {
              await visualizePredictionForImage(i, trainingDataset)
            } catch (error) {
              console.error(`Error visualizing training image ${i}:`, error)
            }
          }

          // Visualize testing images
          for (let i = 0; i < testingDataset.length; i++) {
            try {
              await visualizePredictionForImage(i, testingDataset)
            } catch (error) {
              console.error(`Error visualizing testing image ${i}:`, error)
            }
          }
        } catch (error) {
          console.error('Error in visualizePredictions:', error)
        }
      }

      // Extract and cache features for all images
      async function extractAndCacheFeatures() {
        if (!featureExtractor || trainingDataset.length === 0) return

        const isGraphModel = featureExtractor && 'execute' in featureExtractor
        log('Extracting and caching features for training images...', 'info')

        for (const imgData of trainingDataset) {
          // Skip if features already cached
          if (imgData.features) continue

          let features
          if (isGraphModel) {
            features = featureExtractor.execute(
              { 'inputs:0': imgData.tensor },
              'Identity:0',
            )
          } else {
            features = featureExtractor.predict(imgData.tensor)
          }

          // Cache the features
          imgData.features = features
        }

        log('Features cached for all images', 'success')
      }

      // Clear cached features (e.g., when images change)
      function clearCachedFeatures(dataset) {
        for (const imgData of dataset) {
          if (imgData.features) {
            imgData.features.dispose()
            imgData.features = null
          }
        }
      }

      // Evaluate on testing dataset
      async function evaluateOnTesting() {
        if (!detectionModel || testingDataset.length === 0) {
          // Set test losses to '-' if no testing data
          document.getElementById('testTotalLossValue').textContent = '-'
          document.getElementById('testBoxLossValue').textContent = '-'
          document.getElementById('testClassLossValue').textContent = '-'
          return
        }

        const isGraphModel = featureExtractor && 'execute' in featureExtractor
        const featuresList = []
        const boxesList = []
        const classesList = []

        for (const imgData of testingDataset) {
          let features
          if (imgData.features) {
            features = imgData.features.clone()
          } else {
            if (isGraphModel) {
              features = featureExtractor.execute(
                { 'inputs:0': imgData.tensor },
                'Identity:0',
              )
            } else {
              features = featureExtractor.predict(imgData.tensor)
            }
          }
          featuresList.push(features)
          boxesList.push(imgData.box)
          classesList.push(imgData.class)
        }

        const xs = tf.concat(featuresList, 0)
        const boxTargets = tf.concat(boxesList, 0)
        const classTargets = tf.concat(classesList, 0)

        const boxMask = tf.tensor1d(
          testingDataset.map(imgData => (imgData.isNoObject ? 0 : 1)),
        )
        const boxMaskExpanded = boxMask.expandDims(1)

        const [boxPred, classPred] = detectionModel.predict(xs)

        // Check if predictions contain NaN
        const boxPredData = await boxPred.data()
        const classPredData = await classPred.data()

        let hasNaN = false
        for (let i = 0; i < boxPredData.length; i++) {
          if (isNaN(boxPredData[i]) || !isFinite(boxPredData[i])) {
            hasNaN = true
            log(`Warning: NaN in test box prediction at index ${i}`, 'error')
            break
          }
        }
        if (!hasNaN) {
          for (let i = 0; i < classPredData.length; i++) {
            if (isNaN(classPredData[i]) || !isFinite(classPredData[i])) {
              hasNaN = true
              log(
                `Warning: NaN in test class prediction at index ${i}`,
                'error',
              )
              break
            }
          }
        }

        if (hasNaN) {
          boxPred.dispose()
          classPred.dispose()
          xs.dispose()
          boxTargets.dispose()
          classTargets.dispose()
          boxMask.dispose()
          boxMaskExpanded.dispose()
          featuresList.forEach(f => f.dispose())
          document.getElementById('testTotalLossValue').textContent = '-'
          document.getElementById('testBoxLossValue').textContent = '-'
          document.getElementById('testClassLossValue').textContent = '-'
          return
        }

        const boxDiff = boxTargets.sub(boxPred)
        const boxSquared = boxDiff.square()
        const maskedBoxLoss = boxSquared.mul(boxMaskExpanded)
        let boxLoss = maskedBoxLoss.mean().arraySync()

        const classLossTensor = tf.losses.softmaxCrossEntropy(
          classTargets,
          classPred,
        )
        let classLoss = classLossTensor.arraySync()
        let totalLoss = boxLoss * 1.0 + classLoss * 0.5

        // Check for NaN values
        if (isNaN(boxLoss) || isNaN(classLoss) || isNaN(totalLoss)) {
          log('Warning: NaN detected in test loss values', 'error')
          boxLoss = isNaN(boxLoss) ? 0 : boxLoss
          classLoss = isNaN(classLoss) ? 0 : classLoss
          totalLoss = isNaN(totalLoss) ? 0 : totalLoss
        }

        document.getElementById('testTotalLossValue').textContent = isNaN(
          totalLoss,
        )
          ? '-'
          : totalLoss.toFixed(4)
        document.getElementById('testBoxLossValue').textContent = isNaN(boxLoss)
          ? '-'
          : boxLoss.toFixed(4)
        document.getElementById('testClassLossValue').textContent = isNaN(
          classLoss,
        )
          ? '-'
          : classLoss.toFixed(4)

        // Cleanup
        xs.dispose()
        boxTargets.dispose()
        classTargets.dispose()
        boxMask.dispose()
        boxPred.dispose()
        classPred.dispose()
        classLossTensor.dispose()
        featuresList.forEach(f => f.dispose())
      }

      // Training loop - trains on training images only
      async function trainEpoch() {
        if (!isTraining || !detectionModel || trainingDataset.length === 0)
          return

        try {
          // Update learning rate if changed
          const newLearningRate = parseFloat(learningRateInput.value) || 1e-4
          if (Math.abs(newLearningRate - currentLearningRate) > 1e-7) {
            updateModelLearningRate(newLearningRate)
          }

          // Collect all features and targets (use cached features if available)
          const featuresList = []
          const boxesList = []
          const classesList = []

          const isGraphModel = featureExtractor && 'execute' in featureExtractor

          for (const imgData of trainingDataset) {
            // Use cached features if available, otherwise extract on the fly
            let features
            if (imgData.features) {
              // Use cached features (clone to avoid disposal issues)
              features = imgData.features.clone()
            } else {
              // Extract features if not cached (shouldn't happen in normal flow)
              if (isGraphModel) {
                features = featureExtractor.execute(
                  { 'inputs:0': imgData.tensor },
                  'Identity:0',
                )
              } else {
                features = featureExtractor.predict(imgData.tensor)
              }
            }

            featuresList.push(features)
            boxesList.push(imgData.box)
            classesList.push(imgData.class)
          }

          // Concatenate into batch
          const xs = tf.concat(featuresList, 0)
          const boxTargets = tf.concat(boxesList, 0)
          const classTargets = tf.concat(classesList, 0)

          // Validate inputs - check for NaN in features
          const xsData = await xs.data()
          let hasInvalidInput = false
          for (let i = 0; i < xsData.length; i++) {
            if (isNaN(xsData[i]) || !isFinite(xsData[i])) {
              hasInvalidInput = true
              log(
                `Warning: Invalid feature value at index ${i}: ${xsData[i]}`,
                'error',
              )
              break
            }
          }

          if (hasInvalidInput) {
            log(
              'Error: Invalid input features detected, skipping this epoch',
              'error',
            )
            xs.dispose()
            boxTargets.dispose()
            classTargets.dispose()
            boxMask.dispose()
            featuresList.forEach(f => f.dispose())
            await new Promise(resolve => setTimeout(resolve, 100))
            if (isTraining) {
              await trainEpoch()
            }
            return
          }

          // Create mask for box loss: 0 for "no object" images, 1 for images with objects
          const boxMask = tf.tensor1d(
            trainingDataset.map(imgData => (imgData.isNoObject ? 0 : 1)),
          )
          const boxMaskExpanded = boxMask.expandDims(1) // [batch, 1] to broadcast to [batch, 4]

          // Train on batch with masked box loss
          const optimizer = detectionModel.optimizer
          let boxLoss, classLoss, totalLoss

          // Get loss values for metrics (before applying gradients)
          const [boxPredForMetrics, classPredForMetrics] =
            detectionModel.predict(xs)

          // Check if predictions contain NaN
          const boxPredData = await boxPredForMetrics.data()
          const classPredData = await classPredForMetrics.data()

          let hasNaN = false
          for (let i = 0; i < boxPredData.length; i++) {
            if (isNaN(boxPredData[i]) || !isFinite(boxPredData[i])) {
              hasNaN = true
              break
            }
          }
          if (!hasNaN) {
            for (let i = 0; i < classPredData.length; i++) {
              if (isNaN(classPredData[i]) || !isFinite(classPredData[i])) {
                hasNaN = true
                break
              }
            }
          }

          if (hasNaN) {
            log(
              'Warning: Model predictions contain NaN, skipping this epoch',
              'error',
            )
            boxPredForMetrics.dispose()
            classPredForMetrics.dispose()
            xs.dispose()
            boxTargets.dispose()
            classTargets.dispose()
            boxMask.dispose()
            boxMaskExpanded.dispose()
            featuresList.forEach(f => f.dispose())
            // Wait a bit before retrying
            await new Promise(resolve => setTimeout(resolve, 100))
            if (isTraining) {
              await trainEpoch()
            }
            return
          }

          const boxDiffForMetrics = boxTargets.sub(boxPredForMetrics)
          const boxSquaredForMetrics = boxDiffForMetrics.square()
          const maskedBoxLossForMetrics =
            boxSquaredForMetrics.mul(boxMaskExpanded)
          boxLoss = maskedBoxLossForMetrics.mean().arraySync()

          const classLossTensorForMetrics = tf.losses.softmaxCrossEntropy(
            classTargets,
            classPredForMetrics,
          )
          classLoss = classLossTensorForMetrics.arraySync()
          totalLoss = boxLoss * 1.0 + classLoss * 0.5

          // Check for NaN values
          if (isNaN(boxLoss) || isNaN(classLoss) || isNaN(totalLoss)) {
            log('Warning: NaN detected in loss values', 'error')
            log(`Box loss: ${boxLoss}, Class loss: ${classLoss}`, 'error')
            boxLoss = isNaN(boxLoss) ? 0 : boxLoss
            classLoss = isNaN(classLoss) ? 0 : classLoss
            totalLoss = isNaN(totalLoss) ? 0 : totalLoss
          }

          // Define cost function that computes masked loss
          // Note: boxMaskExpanded, xs, boxTargets, classTargets are used but not disposed by tidy
          // since they're created outside the tidy scope
          const cost = () => {
            return tf.tidy(() => {
              const [boxPred, classPred] = detectionModel.predict(xs)

              // Compute masked box loss: only penalize when there's an object
              const boxDiff = boxTargets.sub(boxPred)
              const boxSquared = boxDiff.square()
              const maskedBoxLoss = boxSquared.mul(boxMaskExpanded)

              // Compute class loss using softmaxCrossEntropy (expects logits)
              const classLossTensor = tf.losses.softmaxCrossEntropy(
                classTargets,
                classPred,
              )

              // Total loss with weights
              const totalLoss = maskedBoxLoss
                .mean()
                .mul(1.0)
                .add(classLossTensor.mul(0.5))

              // Clip gradients to prevent exploding gradients
              // This is done by clipping the loss value itself
              return tf.clipByValue(totalLoss, -100, 100)
            })
          }

          // Apply gradients with gradient clipping
          try {
            optimizer.minimize(cost)
          } catch (error) {
            log(`Error during optimization: ${error.message}`, 'error')
            // Cleanup and skip this epoch
            boxPredForMetrics.dispose()
            classPredForMetrics.dispose()
            classLossTensorForMetrics.dispose()
            maskedBoxLossForMetrics.dispose()
            boxDiffForMetrics.dispose()
            boxSquaredForMetrics.dispose()
            boxMaskExpanded.dispose()
            xs.dispose()
            boxTargets.dispose()
            classTargets.dispose()
            boxMask.dispose()
            featuresList.forEach(f => f.dispose())
            await new Promise(resolve => setTimeout(resolve, 100))
            if (isTraining) {
              await trainEpoch()
            }
            return
          }

          // Cleanup tensors used for metrics (dispose after optimizer is done)
          boxPredForMetrics.dispose()
          classPredForMetrics.dispose()
          classLossTensorForMetrics.dispose()
          maskedBoxLossForMetrics.dispose()
          boxDiffForMetrics.dispose()
          boxSquaredForMetrics.dispose()
          boxMaskExpanded.dispose()

          // Cleanup
          xs.dispose()
          boxTargets.dispose()
          classTargets.dispose()
          boxMask.dispose()
          featuresList.forEach(f => f.dispose())

          currentEpoch++

          document.getElementById('epochValue').textContent = currentEpoch
          document.getElementById('trainTotalLossValue').textContent = isNaN(
            totalLoss,
          )
            ? '-'
            : totalLoss.toFixed(4)
          document.getElementById('trainBoxLossValue').textContent = isNaN(
            boxLoss,
          )
            ? '-'
            : boxLoss.toFixed(4)
          document.getElementById('trainClassLossValue').textContent = isNaN(
            classLoss,
          )
            ? '-'
            : classLoss.toFixed(4)

          // Evaluate on testing dataset
          await evaluateOnTesting()

          const lossStr = isNaN(totalLoss) ? 'NaN' : totalLoss.toFixed(4)
          const boxLossStr = isNaN(boxLoss) ? 'NaN' : boxLoss.toFixed(4)
          const classLossStr = isNaN(classLoss) ? 'NaN' : classLoss.toFixed(4)
          statusDiv.textContent = `Epoch ${currentEpoch}: Train Loss = ${lossStr} (Box: ${boxLossStr}, Class: ${classLossStr})`

          // Visualize predictions after each epoch
          await visualizePredictions()

          // Small delay to allow UI to update
          await new Promise(resolve => setTimeout(resolve, 10))

          // Continue training
          if (isTraining) {
            await trainEpoch()
          }
        } catch (error) {
          log(`Training error: ${error.message}`, 'error')
          statusDiv.textContent = `Error: ${error.message}`
          isTraining = false
          startBtn.disabled = false
          stopBtn.disabled = true
          drawBoxBtn.disabled = false
          learningRateInput.disabled = false
        }
      }

      // Event listeners

      drawBoxBtn.addEventListener('click', () => {
        isDrawingMode = !isDrawingMode
        if (isDrawingMode) {
          drawBoxBtn.textContent = 'Exit Draw Mode'
          drawBoxBtn.style.background = '#e74c3c'
          trainingSection.classList.add('drawing-mode')
          testingSection.classList.add('drawing-mode')
          statusDiv.textContent =
            'Draw mode: Click and drag on images to mark target boxes'
        } else {
          drawBoxBtn.textContent = 'Draw Target Box'
          drawBoxBtn.style.background = '#3498db'
          trainingSection.classList.remove('drawing-mode')
          testingSection.classList.remove('drawing-mode')
          statusDiv.textContent = 'Draw mode exited'
        }
      })

      startBtn.addEventListener('click', async () => {
        if (trainingDataset.length === 0) {
          alert('Please load training images first')
          return
        }

        // Check if all training images have target boxes (except those marked as "no object")
        const missingBoxes = trainingDataset.filter(
          imgData => !imgData.isNoObject && !loadTargetBox(imgData.name),
        )
        if (missingBoxes.length > 0) {
          alert(
            `Please mark target boxes for training images with objects, or mark them as "No Object". ${missingBoxes.length} image(s) missing boxes.`,
          )
          return
        }

        isTraining = true
        // Don't reset epoch counter - continue from where we left off
        startBtn.disabled = true
        stopBtn.disabled = false
        learningRateInput.disabled = true
        statusDiv.textContent = `Training started on ${trainingDataset.length} training image(s)...`
        log(
          `Training started on ${trainingDataset.length} training image(s)`,
          'success',
        )

        // Extract and cache features once before training starts
        await extractAndCacheFeatures()

        // Show initial predictions before training
        if (detectionModel) {
          await visualizePredictions()
        }

        trainEpoch()
      })

      stopBtn.addEventListener('click', () => {
        isTraining = false
        startBtn.disabled = false
        stopBtn.disabled = true
        drawBoxBtn.disabled =
          trainingDataset.length === 0 && testingDataset.length === 0
        learningRateInput.disabled = false
        statusDiv.textContent = `Training stopped. Processed ${currentEpoch} epochs.`
        log('Training stopped', 'info')
      })

      // Toggle image names visibility
      const showImageNamesToggle = document.getElementById(
        'showImageNamesToggle',
      )

      // Function to update visibility based on checkbox state
      function updateImageNamesVisibility() {
        if (showImageNamesToggle.checked) {
          trainingSection.classList.remove('hide-image-names')
          testingSection.classList.remove('hide-image-names')
        } else {
          trainingSection.classList.add('hide-image-names')
          testingSection.classList.add('hide-image-names')
        }
      }

      // Load saved preference from localStorage
      const savedShowNames = localStorage.getItem('showImageNames')
      if (savedShowNames !== null) {
        showImageNamesToggle.checked = savedShowNames === 'true'
      }

      // Apply initial state
      updateImageNamesVisibility()

      // Update on change and save preference
      showImageNamesToggle.addEventListener('change', () => {
        localStorage.setItem(
          'showImageNames',
          showImageNamesToggle.checked.toString(),
        )
        updateImageNamesVisibility()
      })

      // Update image grid columns
      function updateImageGridColumns(numColumns) {
        trainingImagesGrid.style.gridTemplateColumns = `repeat(${numColumns}, 1fr)`
        testingImagesGrid.style.gridTemplateColumns = `repeat(${numColumns}, 1fr)`
      }

      // Number of columns control
      const numColumnsInput = document.getElementById('numColumnsInput')

      // Load saved columns from localStorage
      const savedColumns = localStorage.getItem('imageGridColumns')
      if (savedColumns) {
        numColumnsInput.value = savedColumns
        updateImageGridColumns(parseInt(savedColumns, 10))
      } else {
        // Default to 5 columns if no saved preference
        updateImageGridColumns(5)
      }

      numColumnsInput.addEventListener('input', () => {
        const columns = parseInt(numColumnsInput.value, 10) || 5
        // Clamp to valid range
        const clampedColumns = Math.max(1, Math.min(10, columns))
        numColumnsInput.value = clampedColumns
        localStorage.setItem('imageGridColumns', clampedColumns.toString())
        updateImageGridColumns(clampedColumns)
      })

      // Event listeners for image inputs
      trainingImageInput.addEventListener('change', loadTrainingImages)
      testingImageInput.addEventListener('change', loadTestingImages)

      // Export annotations button
      const exportBtn = document.getElementById('exportAnnotationsBtn')
      exportBtn.addEventListener('click', exportAnnotations)

      // Import annotations button
      const importBtn = document.getElementById('importAnnotationsBtn')
      const importInput = document.getElementById('importAnnotationsInput')
      importBtn.addEventListener('click', () => {
        importInput.click()
      })
      importInput.addEventListener('change', async e => {
        const file = e.target.files[0]
        if (file) {
          try {
            await importAnnotations(file)
            statusDiv.textContent = 'Annotations imported successfully'
          } catch (error) {
            statusDiv.textContent = `Error importing: ${error.message}`
          }
          // Reset input so same file can be imported again
          e.target.value = ''
        }
      })

      // Initialize on load
      window.addEventListener('load', () => {
        initializeModel()
      })
    </script>
  </body>
</html>
