<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SSD Training Demo - Single Image</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.2.0"></script>
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family:
          -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu,
          Cantarell, sans-serif;
        padding: 20px;
        background: #f5f5f5;
        color: #333;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        background: white;
        padding: 30px;
        border-radius: 12px;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
      }

      h1 {
        margin-bottom: 10px;
        color: #2c3e50;
      }

      .subtitle {
        color: #7f8c8d;
        margin-bottom: 30px;
      }

      .upload-section {
        margin-bottom: 30px;
        padding: 20px;
        background: #f8f9fa;
        border-radius: 8px;
      }

      .file-input-wrapper {
        margin-bottom: 15px;
      }

      input[type='file'] {
        margin-bottom: 10px;
      }

      button {
        background: #3498db;
        color: white;
        border: none;
        padding: 12px 24px;
        border-radius: 6px;
        cursor: pointer;
        font-size: 16px;
        margin-right: 10px;
        transition: background 0.3s;
      }

      button:hover:not(:disabled) {
        background: #2980b9;
      }

      button:disabled {
        background: #bdc3c7;
        cursor: not-allowed;
      }

      .status {
        margin-top: 15px;
        padding: 12px;
        background: #e8f4f8;
        border-left: 4px solid #3498db;
        border-radius: 4px;
      }

      .training-info {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 15px;
        margin-bottom: 30px;
      }

      .info-card {
        background: #f8f9fa;
        padding: 15px;
        border-radius: 8px;
        text-align: center;
      }

      .info-label {
        font-size: 12px;
        color: #7f8c8d;
        text-transform: uppercase;
        margin-bottom: 5px;
      }

      .info-value {
        font-size: 24px;
        font-weight: bold;
        color: #2c3e50;
      }

      .images-grid {
        display: grid;
        grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
        gap: 20px;
        margin-bottom: 20px;
      }

      .canvas-container {
        position: relative;
        display: inline-block;
        border: 2px solid #ddd;
        border-radius: 8px;
        overflow: hidden;
        width: 100%;
      }

      .canvas-container.drawing-mode {
        border-color: #3498db;
        box-shadow: 0 0 10px rgba(52, 152, 219, 0.5);
      }

      .image-item {
        display: flex;
        flex-direction: column;
      }

      .image-item .image-name {
        margin-bottom: 8px;
        font-weight: bold;
        color: #2c3e50;
        font-size: 14px;
        word-wrap: break-word;
        word-break: break-all;
        overflow-wrap: break-word;
        max-width: 100%;
        line-height: 1.4;
      }

      .image-item .image-loss {
        margin-top: 8px;
        font-size: 12px;
        color: #7f8c8d;
        padding: 4px 8px;
        background: #f8f9fa;
        border-radius: 4px;
        display: inline-block;
      }

      .image-item .image-loss.high {
        color: #e74c3c;
        background: #fee;
      }

      .image-item .image-loss.medium {
        color: #f39c12;
        background: #fef5e7;
      }

      .image-item .image-loss.low {
        color: #2ecc71;
        background: #eafaf1;
      }

      .image-item .image-ranking {
        position: absolute;
        top: 5px;
        right: 5px;
        background: rgba(52, 152, 219, 0.9);
        color: white;
        padding: 4px 8px;
        border-radius: 4px;
        font-size: 12px;
        font-weight: bold;
        z-index: 10;
      }

      .image-item .image-ranking.worst {
        background: rgba(231, 76, 60, 0.9);
      }

      .image-item canvas {
        display: block;
        max-width: 100%;
        height: auto;
      }

      .prediction-overlay {
        position: absolute;
        top: 0;
        left: 0;
        pointer-events: none;
        z-index: 3;
      }

      .annotation-canvas {
        position: absolute;
        top: 0;
        left: 0;
        cursor: crosshair;
        z-index: 2;
        pointer-events: none;
      }

      .image-item.active {
        border: 3px solid #2ecc71;
        border-radius: 8px;
        padding: 5px;
      }

      .prediction-box {
        position: absolute;
        border: 3px solid #e74c3c;
        background: rgba(231, 76, 60, 0.1);
        box-sizing: border-box;
      }

      .prediction-label {
        position: absolute;
        top: -20px;
        left: 0;
        background: #e74c3c;
        color: white;
        padding: 2px 6px;
        font-size: 12px;
        border-radius: 3px;
        white-space: nowrap;
      }

      .log {
        margin-top: 20px;
        padding: 15px;
        background: #2c3e50;
        color: #ecf0f1;
        border-radius: 8px;
        font-family: 'Courier New', monospace;
        font-size: 12px;
        max-height: 200px;
        overflow-y: auto;
      }

      .log-entry {
        margin-bottom: 5px;
      }

      .log-entry.success {
        color: #2ecc71;
      }

      .log-entry.error {
        color: #e74c3c;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>ðŸš€ SSD Training Demo</h1>
      <p class="subtitle">
        Train on multiple images and watch predictions improve over time
      </p>

      <div class="upload-section">
        <div class="file-input-wrapper">
          <label for="imageInput">Select images (multiple):</label>
          <input type="file" id="imageInput" accept="image/*" multiple />
        </div>
        <div style="margin-top: 10px">
          <button id="startTrainingBtn" disabled>Start Training</button>
          <button id="stopTrainingBtn" disabled>Stop Training</button>
          <button id="drawBoxBtn" disabled>Draw Target Box</button>
          <span id="imageCounter" style="margin-left: 10px; padding: 0 10px"
            >0 images loaded</span
          >
        </div>
        <div
          style="
            margin-top: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
          "
        >
          <label for="batchSizeInput">Batch Size (worst images):</label>
          <input
            type="number"
            id="batchSizeInput"
            min="1"
            max="1"
            value="1"
            style="width: 60px; padding: 4px"
          />
          <span style="font-size: 12px; color: #7f8c8d"
            >(Number of images to train on per epoch)</span
          >
        </div>
        <div
          style="
            margin-top: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
          "
        >
          <label for="temperatureInput">Selection Temperature:</label>
          <input
            type="number"
            id="temperatureInput"
            min="0.1"
            max="10"
            step="0.1"
            value="2.0"
            style="width: 60px; padding: 4px"
          />
          <span style="font-size: 12px; color: #7f8c8d"
            >(Lower = favor worst images more, Higher = more random)</span
          >
        </div>
        <div
          style="
            margin-top: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
          "
        >
          <label for="learningRateInput">Learning Rate:</label>
          <input
            type="number"
            id="learningRateInput"
            min="1e-6"
            max="1e-2"
            step="1e-5"
            value="0.0001"
            style="width: 80px; padding: 4px"
          />
          <span style="font-size: 12px; color: #7f8c8d"
            >(Higher = faster but less stable)</span
          >
        </div>
        <div
          style="
            margin-top: 10px;
            display: flex;
            align-items: center;
            gap: 10px;
          "
        >
          <label for="selectionStrategy">Selection Strategy:</label>
          <select id="selectionStrategy" style="padding: 4px">
            <option value="weighted">Weighted Random (Current)</option>
            <option value="hard-mining">Hard Negative Mining</option>
            <option value="diverse">Diverse Batch (Mix of difficulties)</option>
            <option value="curriculum">Curriculum Learning</option>
          </select>
        </div>
        <div class="status" id="status">Please select images to begin</div>
      </div>

      <div class="training-info">
        <div class="info-card">
          <div class="info-label">Epoch</div>
          <div class="info-value" id="epochValue">0</div>
        </div>
        <div class="info-card">
          <div class="info-label">Loss</div>
          <div class="info-value" id="lossValue">-</div>
        </div>
        <div class="info-card">
          <div class="info-label">Box Loss</div>
          <div class="info-value" id="boxLossValue">-</div>
        </div>
        <div class="info-card">
          <div class="info-label">Class Loss</div>
          <div class="info-value" id="classLossValue">-</div>
        </div>
      </div>

      <div class="images-grid" id="imagesGrid"></div>

      <div class="log" id="log"></div>
    </div>

    <script>
      // Global variables
      let detectionModel = null
      let featureExtractor = null
      let isTraining = false
      let currentEpoch = 0
      let imageElement = null
      let imageTensor = null
      let targetBox = null // [x, y, w, h] normalized coordinates
      let targetClass = null // one-hot encoded class
      let currentImageFileName = null

      // Multiple images support
      let imageDataset = [] // Array of {file, name, element, tensor, box, class, boxLoss, totalLoss, rank}
      let currentImageIndex = 0
      let currentTrainingImageIndex = 0

      // Drawing state
      let isDrawingMode = false
      let isDrawing = false
      let drawStartX = 0
      let drawStartY = 0

      const IMAGE_SIZE = 224
      const NUM_CLASSES = 2 // background + 1 object class
      let currentLearningRate = 1e-4

      // UI elements
      const imageInput = document.getElementById('imageInput')
      const startBtn = document.getElementById('startTrainingBtn')
      const stopBtn = document.getElementById('stopTrainingBtn')
      const drawBoxBtn = document.getElementById('drawBoxBtn')
      const batchSizeInput = document.getElementById('batchSizeInput')
      const temperatureInput = document.getElementById('temperatureInput')
      const learningRateInput = document.getElementById('learningRateInput')
      const selectionStrategySelect =
        document.getElementById('selectionStrategy')
      const imageCounter = document.getElementById('imageCounter')
      const statusDiv = document.getElementById('status')
      const imagesGrid = document.getElementById('imagesGrid')
      const logDiv = document.getElementById('log')

      // Logging utility
      function log(message, type = 'info') {
        const entry = document.createElement('div')
        entry.className = `log-entry ${type}`
        entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`
        logDiv.appendChild(entry)
        logDiv.scrollTop = logDiv.scrollHeight
        console.log(message)
      }

      // LocalStorage utilities
      function getStorageKey(fileName) {
        return `ssd_target_box_${fileName}`
      }

      function saveTargetBox(fileName, box) {
        if (!fileName) return
        const key = getStorageKey(fileName)
        localStorage.setItem(key, JSON.stringify(box))
        log(`Target box saved for ${fileName}`, 'success')
      }

      function loadTargetBox(fileName) {
        if (!fileName) return null
        const key = getStorageKey(fileName)
        const saved = localStorage.getItem(key)
        if (saved) {
          try {
            return JSON.parse(saved)
          } catch (e) {
            log(`Error loading saved box: ${e.message}`, 'error')
            return null
          }
        }
        return null
      }

      function clearTargetBox(fileName) {
        if (!fileName) return
        const key = getStorageKey(fileName)
        localStorage.removeItem(key)
        log(`Target box cleared for ${fileName}`, 'info')
      }

      // Update target box tensor from normalized coordinates
      function updateTargetBox(centerX, centerY, width, height) {
        // Update current display
        targetBox = tf.tensor2d([[centerX, centerY, width, height]])

        // Update dataset entry
        if (imageDataset[currentImageIndex]) {
          // Dispose old tensors
          if (imageDataset[currentImageIndex].box) {
            imageDataset[currentImageIndex].box.dispose()
          }

          imageDataset[currentImageIndex].box = targetBox.clone()
          imageDataset[currentImageIndex].centerX = centerX
          imageDataset[currentImageIndex].centerY = centerY
          imageDataset[currentImageIndex].width = width
          imageDataset[currentImageIndex].height = height
        }

        if (currentImageFileName) {
          saveTargetBox(currentImageFileName, {
            centerX,
            centerY,
            width,
            height,
          })
        }
        log(
          `Target box updated: [${centerX.toFixed(2)}, ${centerY.toFixed(2)}, ${width.toFixed(2)}, ${height.toFixed(2)}]`,
          'info',
        )
        drawTargetBoxForImage(currentImageIndex)
      }

      // Draw target box on a specific image's annotation canvas
      function drawTargetBoxForImage(index) {
        if (index < 0 || index >= imageDataset.length) return
        const imgData = imageDataset[index]
        if (!imgData || !imgData.box || !imgData.canvasElements) return

        const { annotCanvas, imageCanvas } = imgData.canvasElements
        const annotCtx = annotCanvas.getContext('2d')

        annotCtx.clearRect(0, 0, annotCanvas.width, annotCanvas.height)

        imgData.box.array().then(data => {
          const box = data[0]
          const centerX = box[0] * imageCanvas.width
          const centerY = box[1] * imageCanvas.height
          const width = box[2] * imageCanvas.width
          const height = box[3] * imageCanvas.height
          const x1 = centerX - width / 2
          const y1 = centerY - height / 2

          // Draw target box
          annotCtx.strokeStyle = '#2ecc71'
          annotCtx.lineWidth = 3
          annotCtx.setLineDash([5, 5])
          annotCtx.strokeRect(x1, y1, width, height)
          annotCtx.setLineDash([])

          // Draw label
          annotCtx.fillStyle = '#2ecc71'
          annotCtx.fillRect(x1, y1 - 25, 150, 25)
          annotCtx.fillStyle = 'white'
          annotCtx.font = '14px Arial'
          annotCtx.fillText('Target Box (Green)', x1 + 5, y1 - 8)
        })
      }

      // Draw target boxes for all images
      function drawAllTargetBoxes() {
        for (let i = 0; i < imageDataset.length; i++) {
          drawTargetBoxForImage(i)
        }
      }

      // Initialize: Load MobileNet feature extractor
      async function initializeModel() {
        log('Loading MobileNet feature extractor...', 'info')
        statusDiv.textContent = 'Loading MobileNet...'

        try {
          // Load MobileNet v3 feature vector model (local)
          // This is a GraphModel that outputs feature vectors directly
          // Path is absolute from web server root
          const modelUrl =
            '/saved_models/mobilenet-v3-tfjs-large-100-224-feature-vector-v1/model.json'

          log(`Loading from: ${modelUrl}`, 'info')
          const mobilenetGraph = await tf.loadGraphModel(modelUrl)

          // GraphModel outputs features directly [batch, 1280]
          // We'll wrap it in a function that can be used in our LayersModel
          // For now, we'll use it directly in buildDetectionModel
          featureExtractor = mobilenetGraph

          log('MobileNet loaded successfully (GraphModel)', 'success')
          log('Feature vector size: 1280', 'info')

          // Build detection model
          buildDetectionModel()
        } catch (error) {
          log(`Error loading model: ${error.message}`, 'error')
          statusDiv.textContent = `Error: ${error.message}`
          log('Trying alternative model path...', 'info')

          // Fallback: try classification model
          try {
            const altModelUrl =
              '/saved_models/mobilenet-v3-tfjs-large-100-224-classification-v1/model.json'
            log(`Trying: ${altModelUrl}`, 'info')
            const mobilenetGraph = await tf.loadGraphModel(altModelUrl)

            // For classification model, we need to extract features before the classification layer
            // GraphModels don't have layers, so we'll use it as-is and handle in buildDetectionModel
            featureExtractor = mobilenetGraph
            log(
              'MobileNet loaded successfully (fallback, classification model)',
              'success',
            )
            buildDetectionModel()
          } catch (fallbackError) {
            log(`Fallback also failed: ${fallbackError.message}`, 'error')
            statusDiv.textContent = `Error: ${fallbackError.message}. Make sure the model files are in saved_models/ directory.`
          }
        }
      }

      // Build SSD detection head
      function buildDetectionModel() {
        log('Building detection model...', 'info')

        // Check if featureExtractor is a GraphModel
        const isGraphModel = featureExtractor && 'execute' in featureExtractor

        if (isGraphModel) {
          // For GraphModel, build a detection head with intermediate layers for better learning
          // Features will be extracted separately in the training loop
          const featureInput = tf.input({ shape: [1280] }) // Feature vector size

          // Shared intermediate layer for better feature learning
          const shared = tf.layers
            .dense({
              units: 256,
              activation: 'relu',
              name: 'shared_layer',
            })
            .apply(featureInput)

          // Bounding box head with intermediate layer
          const boxIntermediate = tf.layers
            .dense({
              units: 128,
              activation: 'relu',
              name: 'box_intermediate',
            })
            .apply(shared)

          const boxHead = tf.layers
            .dense({
              units: 4,
              activation: 'sigmoid',
              name: 'box_head',
            })
            .apply(boxIntermediate)

          // Classification head with intermediate layer
          const classIntermediate = tf.layers
            .dense({
              units: 128,
              activation: 'relu',
              name: 'class_intermediate',
            })
            .apply(shared)

          const classHead = tf.layers
            .dense({
              units: NUM_CLASSES,
              activation: 'softmax',
              name: 'class_head',
            })
            .apply(classIntermediate)

          detectionModel = tf.model({
            inputs: featureInput,
            outputs: [boxHead, classHead],
          })
        } else {
          // For LayersModel, use the original approach with improved architecture
          const input = tf.input({ shape: [IMAGE_SIZE, IMAGE_SIZE, 3] })
          const features = featureExtractor.apply(input)

          // Flatten if needed
          const flattened = tf.layers.flatten().apply(features)

          // Shared intermediate layer for better feature learning
          const shared = tf.layers
            .dense({
              units: 256,
              activation: 'relu',
              name: 'shared_layer',
            })
            .apply(flattened)

          // Bounding box head with intermediate layer
          const boxIntermediate = tf.layers
            .dense({
              units: 128,
              activation: 'relu',
              name: 'box_intermediate',
            })
            .apply(shared)

          const boxHead = tf.layers
            .dense({
              units: 4,
              activation: 'sigmoid',
              name: 'box_head',
            })
            .apply(boxIntermediate)

          // Classification head with intermediate layer
          const classIntermediate = tf.layers
            .dense({
              units: 128,
              activation: 'relu',
              name: 'class_intermediate',
            })
            .apply(shared)

          const classHead = tf.layers
            .dense({
              units: NUM_CLASSES,
              activation: 'softmax',
              name: 'class_head',
            })
            .apply(classIntermediate)

          detectionModel = tf.model({
            inputs: input,
            outputs: [boxHead, classHead],
          })
        }

        // Compile model with initial learning rate
        updateModelLearningRate(currentLearningRate)

        log('Detection model built and compiled', 'success')
        log(`Model summary: ${detectionModel.countParams()} parameters`, 'info')
      }

      // Update model learning rate dynamically
      function updateModelLearningRate(lr) {
        if (!detectionModel) return
        currentLearningRate = lr
        const optimizer = tf.train.adam(lr)
        detectionModel.compile({
          optimizer: optimizer,
          loss: ['meanSquaredError', 'categoricalCrossentropy'],
          lossWeights: [1.0, 0.5], // Weight box loss more
          metrics: ['accuracy'],
        })
        log(`Learning rate updated to ${lr}`, 'info')
      }

      // Load a single image into dataset
      function loadImageIntoDataset(file, index) {
        return new Promise((resolve, reject) => {
          const reader = new FileReader()
          reader.onload = async event => {
            const img = new Image()
            img.onload = async () => {
              // Preprocess image for model
              const tensor = tf.browser
                .fromPixels(img)
                .resizeNearestNeighbor([IMAGE_SIZE, IMAGE_SIZE])
                .toFloat()
                .div(127.5)
                .sub(1.0)
                .expandDims(0)

              // Load saved target box or use default
              const savedBox = loadTargetBox(file.name)
              let centerX, centerY, width, height

              if (savedBox) {
                centerX = savedBox.centerX
                centerY = savedBox.centerY
                width = savedBox.width
                height = savedBox.height
              } else {
                centerX = 0.5
                centerY = 0.5
                width = 0.4
                height = 0.4
              }

              const box = tf.tensor2d([[centerX, centerY, width, height]])
              const cls = tf.tensor2d([[0, 1]])

              imageDataset[index] = {
                file,
                name: file.name,
                element: img,
                tensor,
                box,
                class: cls,
                centerX,
                centerY,
                width,
                height,
              }

              resolve()
            }
            img.onerror = reject
            img.src = event.target.result
          }
          reader.onerror = reject
          reader.readAsDataURL(file)
        })
      }

      // Display all images in grid
      function displayAllImages() {
        if (imageDataset.length === 0) {
          imagesGrid.innerHTML = ''
          return
        }

        imagesGrid.innerHTML = ''

        imageDataset.forEach((imgData, index) => {
          // Create container for this image
          const imageItem = document.createElement('div')
          imageItem.className = 'image-item'
          imageItem.dataset.index = index

          // Image name
          const nameDiv = document.createElement('div')
          nameDiv.className = 'image-name'
          nameDiv.textContent = imgData.name
          imageItem.appendChild(nameDiv)

          // Loss display
          const lossDiv = document.createElement('div')
          lossDiv.className = 'image-loss'
          lossDiv.textContent = 'Box Loss: -'
          imageItem.appendChild(lossDiv)

          // Canvas container
          const canvasContainer = document.createElement('div')
          canvasContainer.className = 'canvas-container'
          canvasContainer.dataset.index = index
          canvasContainer.style.position = 'relative'

          // Ranking badge
          const rankingBadge = document.createElement('div')
          rankingBadge.className = 'image-ranking'
          rankingBadge.textContent = 'Rank -'
          canvasContainer.appendChild(rankingBadge)

          // Create canvases
          const imageCanvas = document.createElement('canvas')
          const annotCanvas = document.createElement('canvas')
          annotCanvas.className = 'annotation-canvas'
          const predCanvas = document.createElement('canvas')
          predCanvas.className = 'prediction-overlay'

          // Set canvas sizes
          imageCanvas.width = imgData.element.width
          imageCanvas.height = imgData.element.height
          annotCanvas.width = imgData.element.width
          annotCanvas.height = imgData.element.height
          predCanvas.width = imgData.element.width
          predCanvas.height = imgData.element.height

          // Draw image
          const ctx = imageCanvas.getContext('2d')
          ctx.drawImage(imgData.element, 0, 0)

          // Store canvas references
          imgData.canvasElements = {
            imageCanvas,
            annotCanvas,
            predCanvas,
            container: canvasContainer,
            item: imageItem,
            lossElement: lossDiv,
            rankingElement: rankingBadge,
          }

          canvasContainer.appendChild(imageCanvas)
          canvasContainer.appendChild(annotCanvas)
          canvasContainer.appendChild(predCanvas)
          imageItem.appendChild(canvasContainer)

          // Click handler to select image for drawing
          canvasContainer.addEventListener('click', () => {
            if (isDrawingMode) {
              // Remove active class from all
              document.querySelectorAll('.image-item').forEach(item => {
                item.classList.remove('active')
              })
              // Add active class to clicked image
              imageItem.classList.add('active')
              currentImageIndex = index
              currentImageFileName = imgData.name
              imageElement = imgData.element
              imageTensor = imgData.tensor
              targetBox = imgData.box
              targetClass = imgData.class
              log(
                `Selected image ${index + 1}: ${imgData.name} for drawing`,
                'info',
              )
            }
          })

          // Attach drawing handlers to this image's canvas
          attachDrawingHandlers(imgData, index)

          imagesGrid.appendChild(imageItem)
        })

        // Draw target boxes for all images
        drawAllTargetBoxes()

        // Update UI
        imageCounter.textContent = `${imageDataset.length} image(s) loaded`
        statusDiv.textContent = `${imageDataset.length} image(s) loaded. Click "Draw Target Box" then click on an image to annotate it.`
        startBtn.disabled = false
        drawBoxBtn.disabled = false

        // Set first image as active if drawing mode
        if (isDrawingMode && imageDataset.length > 0) {
          currentImageIndex = 0
          const firstItem = imageDataset[0].canvasElements?.item
          if (firstItem) {
            firstItem.classList.add('active')
            currentImageFileName = imageDataset[0].name
            imageElement = imageDataset[0].element
            imageTensor = imageDataset[0].tensor
            targetBox = imageDataset[0].box
            targetClass = imageDataset[0].class
          }
        }
      }

      // Handle multiple image selection
      imageInput.addEventListener('change', async e => {
        const files = Array.from(e.target.files)
        if (files.length === 0) return

        log(`Loading ${files.length} image(s)...`, 'info')
        statusDiv.textContent = `Loading ${files.length} image(s)...`

        // Clear previous dataset
        imageDataset.forEach(item => {
          if (item.tensor) item.tensor.dispose()
          if (item.box) item.box.dispose()
          if (item.class) item.class.dispose()
        })
        imageDataset = []

        // Load all images
        try {
          for (let i = 0; i < files.length; i++) {
            await loadImageIntoDataset(files[i], i)
            log(`Loaded ${i + 1}/${files.length}: ${files[i].name}`, 'success')
          }

          currentImageIndex = 0
          displayAllImages()

          // Update batch size input max and ensure it's enabled
          batchSizeInput.max = files.length
          batchSizeInput.disabled = false
          if (parseInt(batchSizeInput.value) > files.length) {
            batchSizeInput.value = files.length
          }

          log(`All ${files.length} images loaded successfully`, 'success')
        } catch (error) {
          log(`Error loading images: ${error.message}`, 'error')
          statusDiv.textContent = `Error: ${error.message}`
        }
      })

      // Calculate loss for a single image
      async function calculateImageLoss(imgData) {
        const isGraphModel = featureExtractor && 'execute' in featureExtractor
        let xs, ys

        if (isGraphModel) {
          const features = featureExtractor.execute(
            { 'inputs:0': imgData.tensor },
            'Identity:0',
          )
          xs = features
          ys = [imgData.box, imgData.class]
        } else {
          xs = imgData.tensor
          ys = [imgData.box, imgData.class]
        }

        // Get predictions
        const [predBoxes, predClasses] = detectionModel.predict(xs)

        // Calculate box loss (MSE)
        const boxLoss = tf.losses.meanSquaredError(imgData.box, predBoxes)
        const boxLossValue = await boxLoss.data()

        // Calculate class loss (categorical crossentropy)
        const classLoss = tf.losses.softmaxCrossEntropy(
          imgData.class,
          predClasses,
        )
        const classLossValue = await classLoss.data()

        const totalLoss = boxLossValue[0] + classLossValue[0] * 0.5

        // Store losses in image data
        imgData.boxLoss = boxLossValue[0]
        imgData.classLoss = classLossValue[0]
        imgData.totalLoss = totalLoss

        // Cleanup
        if (isGraphModel && xs !== imgData.tensor) {
          xs.dispose()
        }
        predBoxes.dispose()
        predClasses.dispose()
        boxLoss.dispose()
        classLoss.dispose()

        return {
          totalLoss,
          boxLoss: boxLossValue[0],
          classLoss: classLossValue[0],
        }
      }

      // Weighted random selection based on loss (higher loss = higher probability)
      function weightedRandomSelect(losses, batchSize, temperature) {
        // Calculate probabilities using softmax with temperature
        // Higher loss = higher probability, but temperature controls sharpness
        const maxLoss = Math.max(...losses.map(l => l.totalLoss))
        const minLoss = Math.min(...losses.map(l => l.totalLoss))
        const lossRange = maxLoss - minLoss || 1 // Avoid division by zero

        // Normalize losses and apply temperature
        const weights = losses.map(loss => {
          // Normalize loss to [0, 1] range
          const normalized = (loss.totalLoss - minLoss) / lossRange
          // Apply temperature: lower temperature = sharper distribution (favors worst more)
          // Using exponential to make higher losses much more likely
          return Math.exp(normalized / temperature)
        })

        // Calculate probabilities
        const sumWeights = weights.reduce((a, b) => a + b, 0)
        const probabilities = weights.map(w => w / sumWeights)

        // Sample without replacement
        const selectedIndices = []
        const availableIndices = losses.map((_, i) => i)
        const availableProbs = [...probabilities]

        for (let i = 0; i < batchSize && availableIndices.length > 0; i++) {
          // Select one index based on probabilities
          const rand = Math.random()
          let cumulative = 0
          let selectedIdx = -1

          for (let j = 0; j < availableProbs.length; j++) {
            cumulative += availableProbs[j]
            if (rand <= cumulative) {
              selectedIdx = j
              break
            }
          }

          // Fallback to last index if needed
          if (selectedIdx === -1) selectedIdx = availableProbs.length - 1

          const actualIndex = losses[availableIndices[selectedIdx]].index
          selectedIndices.push(actualIndex)

          // Remove selected index and renormalize probabilities
          availableIndices.splice(selectedIdx, 1)
          availableProbs.splice(selectedIdx, 1)
          const newSum = availableProbs.reduce((a, b) => a + b, 0)
          for (let j = 0; j < availableProbs.length; j++) {
            availableProbs[j] /= newSum
          }
        }

        return selectedIndices
      }

      // Update loss display for a specific image
      function updateImageLossDisplay(index, boxLoss, rank, isWorst) {
        if (index < 0 || index >= imageDataset.length) return
        const imgData = imageDataset[index]
        if (!imgData.canvasElements) return

        // Update loss text
        const lossElement = imgData.canvasElements.lossElement
        if (lossElement) {
          lossElement.textContent = `Box Loss: ${boxLoss.toFixed(4)}`
          // Color code based on loss value
          lossElement.className = 'image-loss'
          if (boxLoss > 0.1) {
            lossElement.classList.add('high')
          } else if (boxLoss > 0.05) {
            lossElement.classList.add('medium')
          } else {
            lossElement.classList.add('low')
          }
        }

        // Update ranking badge
        const rankingElement = imgData.canvasElements.rankingElement
        if (rankingElement) {
          rankingElement.textContent = `Rank ${rank}`
          rankingElement.className = 'image-ranking'
          if (isWorst) {
            rankingElement.classList.add('worst')
            rankingElement.textContent = `Rank ${rank} (Batch)`
          }
        }
      }

      // Hard negative mining: select hardest examples
      function hardNegativeMining(losses, batchSize) {
        // Sort by loss (worst first) and take top N
        const sorted = [...losses].sort((a, b) => b.totalLoss - a.totalLoss)
        return sorted.slice(0, batchSize).map(l => l.index)
      }

      // Diverse batch: mix of high, medium, and low loss images
      function diverseBatchSelection(losses, batchSize) {
        const sorted = [...losses].sort((a, b) => b.totalLoss - a.totalLoss)
        const selected = []
        const third = Math.floor(batchSize / 3)

        // Take worst third
        for (let i = 0; i < third && i < sorted.length; i++) {
          selected.push(sorted[i].index)
        }

        // Take middle third
        const midStart = Math.floor(sorted.length / 3)
        for (let i = 0; i < third && midStart + i < sorted.length; i++) {
          if (!selected.includes(sorted[midStart + i].index)) {
            selected.push(sorted[midStart + i].index)
          }
        }

        // Take best third (or random if we need more)
        const remaining = batchSize - selected.length
        for (let i = 0; i < remaining; i++) {
          const randomIdx = Math.floor(Math.random() * sorted.length)
          if (!selected.includes(sorted[randomIdx].index)) {
            selected.push(sorted[randomIdx].index)
          }
        }

        return selected.slice(0, batchSize)
      }

      // Curriculum learning: gradually increase difficulty
      function curriculumLearning(losses, batchSize, epoch) {
        // Start with easier examples, gradually include harder ones
        const sorted = [...losses].sort((a, b) => b.totalLoss - a.totalLoss)
        const progress = Math.min(epoch / 50, 1.0) // Full curriculum over 50 epochs
        const hardRatio = progress // More hard examples as training progresses

        const hardCount = Math.floor(batchSize * hardRatio)
        const easyCount = batchSize - hardCount

        const selected = []
        // Add hardest examples
        for (let i = 0; i < hardCount && i < sorted.length; i++) {
          selected.push(sorted[i].index)
        }
        // Add easier examples
        for (
          let i = sorted.length - 1;
          i >= sorted.length - easyCount && i >= 0;
          i--
        ) {
          if (!selected.includes(sorted[i].index)) {
            selected.push(sorted[i].index)
          }
        }

        return selected.slice(0, batchSize)
      }

      // Select images using different strategies based on cached losses
      function selectImagesForTraining(batchSize, temperature) {
        // Build losses array from cached values
        const losses = []
        for (let i = 0; i < imageDataset.length; i++) {
          const imgData = imageDataset[i]
          // Use cached loss, or default to high value if not calculated yet
          losses.push({
            index: i,
            totalLoss: imgData.totalLoss ?? 1.0,
            boxLoss: imgData.boxLoss ?? 1.0,
            classLoss: imgData.classLoss ?? 0.0,
          })
        }

        // Sort by total loss (descending - worst first) for ranking display
        losses.sort((a, b) => b.totalLoss - a.totalLoss)

        // Get batch size (ensure it doesn't exceed number of images)
        const actualBatchSize = Math.min(batchSize, imageDataset.length)

        // Select based on strategy
        const strategy = selectionStrategySelect.value
        let selectedIndices

        switch (strategy) {
          case 'hard-mining':
            selectedIndices = hardNegativeMining(losses, actualBatchSize)
            break
          case 'diverse':
            selectedIndices = diverseBatchSelection(losses, actualBatchSize)
            break
          case 'curriculum':
            selectedIndices = curriculumLearning(
              losses,
              actualBatchSize,
              currentEpoch,
            )
            break
          case 'weighted':
          default:
            selectedIndices = weightedRandomSelect(
              losses,
              actualBatchSize,
              temperature,
            )
        }

        // Assign rankings and update displays
        losses.forEach((loss, rank) => {
          const imgData = imageDataset[loss.index]
          imgData.rank = rank + 1 // 1-based ranking
          const isInBatch = selectedIndices.includes(loss.index)
          updateImageLossDisplay(loss.index, loss.boxLoss, rank + 1, isInBatch)
        })

        return selectedIndices
      }

      // Training loop - trains on images one by one, collecting losses during training
      async function trainEpoch() {
        if (!isTraining || !detectionModel || imageDataset.length === 0) return

        try {
          // Get batch size, temperature, and learning rate from inputs
          const batchSize = parseInt(batchSizeInput.value) || 1
          const temperature = parseFloat(temperatureInput.value) || 2.0
          const newLearningRate = parseFloat(learningRateInput.value) || 1e-4

          // Update learning rate if changed (with learning rate decay)
          const decayFactor = 0.999 // Small decay per epoch
          const adjustedLR =
            newLearningRate * Math.pow(decayFactor, currentEpoch)
          if (Math.abs(adjustedLR - currentLearningRate) > 1e-7) {
            updateModelLearningRate(adjustedLR)
          }

          // On first epoch, train on all images to collect initial losses
          let selectedIndices
          let actualBatchSize
          if (currentEpoch === 0) {
            // First epoch: train on all images to collect losses
            selectedIndices = imageDataset.map((_, i) => i)
            actualBatchSize = imageDataset.length
            statusDiv.textContent = `Initializing: training on all ${imageDataset.length} images to collect losses...`
          } else {
            // Subsequent epochs: select based on cached losses and strategy
            actualBatchSize = Math.min(batchSize, imageDataset.length)
            selectedIndices = selectImagesForTraining(
              actualBatchSize,
              temperature,
            )
          }

          const isGraphModel = featureExtractor && 'execute' in featureExtractor
          let totalBoxLoss = 0
          let totalClassLoss = 0
          let totalLossSum = 0

          // Train on each selected image one by one, collecting losses
          for (const index of selectedIndices) {
            const imgData = imageDataset[index]
            let xs, ys

            if (isGraphModel) {
              // Extract features using GraphModel (frozen, no gradients)
              const features = featureExtractor.execute(
                { 'inputs:0': imgData.tensor },
                'Identity:0',
              )
              xs = features
              ys = [imgData.box, imgData.class]
            } else {
              // For LayersModel, use image directly
              xs = imgData.tensor
              ys = [imgData.box, imgData.class]
            }

            // Train on single image and collect loss
            const history = await detectionModel.fit(xs, ys, {
              epochs: 1,
              batchSize: 1,
              verbose: 0,
            })

            const boxLoss = history.history.loss[0]
            const classLoss = history.history.loss[1] || 0
            const totalLoss = boxLoss + classLoss

            // Store the actual training loss for this image
            imgData.totalLoss = totalLoss
            imgData.boxLoss = boxLoss
            imgData.classLoss = classLoss

            // Accumulate for average display
            totalBoxLoss += boxLoss
            totalClassLoss += classLoss
            totalLossSum += totalLoss

            // Cleanup
            if (isGraphModel && xs !== imgData.tensor) {
              xs.dispose()
            }
          }

          currentEpoch++

          // Calculate averages for display
          const avgBoxLoss = totalBoxLoss / actualBatchSize
          const avgClassLoss = totalClassLoss / actualBatchSize
          const avgTotalLoss = totalLossSum / actualBatchSize

          // Update UI
          document.getElementById('epochValue').textContent = currentEpoch
          document.getElementById('lossValue').textContent =
            avgTotalLoss.toFixed(4)
          document.getElementById('boxLossValue').textContent =
            avgBoxLoss.toFixed(4)
          document.getElementById('classLossValue').textContent =
            avgClassLoss.toFixed(4)

          // Update status with strategy info
          const strategy = selectionStrategySelect.value
          const strategyName =
            {
              'weighted': 'Weighted Random',
              'hard-mining': 'Hard Mining',
              'diverse': 'Diverse Batch',
              'curriculum': 'Curriculum',
            }[strategy] || 'Weighted'

          if (currentEpoch === 1) {
            statusDiv.textContent = `Initialization complete. Using ${strategyName} (Epoch: ${currentEpoch}, LR: ${currentLearningRate.toFixed(6)}, Loss: ${avgTotalLoss.toFixed(4)})`
          } else {
            statusDiv.textContent = `${strategyName}: ${actualBatchSize} image(s) (Epoch: ${currentEpoch}, LR: ${currentLearningRate.toFixed(6)}, Loss: ${avgTotalLoss.toFixed(4)})`
          }

          // Update rankings based on newly collected losses (only if not first epoch)
          if (currentEpoch > 0) {
            selectImagesForTraining(actualBatchSize, temperature)
          }

          // Run inference and visualize on all images
          await visualizePredictions()

          // Continue training
          if (isTraining) {
            trainEpoch()
          }
        } catch (error) {
          log(`Training error: ${error.message}`, 'error')
          stopTraining()
        }
      }

      // Visualize predictions on all images
      async function visualizePredictions() {
        if (!detectionModel || imageDataset.length === 0) return

        try {
          const isGraphModel = featureExtractor && 'execute' in featureExtractor

          // Visualize predictions for all images
          for (let i = 0; i < imageDataset.length; i++) {
            const imgData = imageDataset[i]
            if (!imgData.canvasElements) continue

            const { predCanvas, imageCanvas } = imgData.canvasElements
            const predCtx = predCanvas.getContext('2d')

            let modelInput
            if (isGraphModel) {
              const features = featureExtractor.execute(
                { 'inputs:0': imgData.tensor },
                'Identity:0',
              )
              modelInput = features
            } else {
              modelInput = imgData.tensor
            }

            const [predBoxes, predClasses] = detectionModel.predict(modelInput)

            // Cleanup if GraphModel
            if (isGraphModel && modelInput !== imgData.tensor) {
              modelInput.dispose()
            }

            // Get values
            const boxData = await predBoxes.data()
            const classData = await predClasses.data()

            // Clear previous predictions
            predCtx.clearRect(0, 0, predCanvas.width, predCanvas.height)

            // Draw predicted bounding box
            const x = boxData[0] * imageCanvas.width
            const y = boxData[1] * imageCanvas.height
            const w = boxData[2] * imageCanvas.width
            const h = boxData[3] * imageCanvas.height

            // Convert center coordinates to top-left
            const x1 = x - w / 2
            const y1 = y - h / 2

            // Draw box
            predCtx.strokeStyle = '#e74c3c'
            predCtx.lineWidth = 3
            predCtx.strokeRect(x1, y1, w, h)

            // Draw label
            const confidence = classData[1] // Object class probability
            predCtx.fillStyle = '#e74c3c'
            predCtx.fillRect(x1, y1 - 20, 100, 20)
            predCtx.fillStyle = 'white'
            predCtx.font = '12px Arial'
            predCtx.fillText(
              `Object: ${(confidence * 100).toFixed(1)}%`,
              x1 + 5,
              y1 - 5,
            )

            // Cleanup
            predBoxes.dispose()
            predClasses.dispose()
          }
        } catch (error) {
          log(`Visualization error: ${error.message}`, 'error')
        }
      }

      // Start training
      startBtn.addEventListener('click', () => {
        if (!detectionModel || imageDataset.length === 0) {
          log('Please load images first', 'error')
          return
        }

        isTraining = true
        currentEpoch = 0
        currentTrainingImageIndex = 0
        startBtn.disabled = true
        stopBtn.disabled = false
        drawBoxBtn.disabled = true
        batchSizeInput.disabled = true
        const batchSize = parseInt(batchSizeInput.value) || 1
        statusDiv.textContent = `Training started on ${imageDataset.length} image(s) with batch size ${batchSize}. Calculating initial rankings...`
        log(
          `Training started on ${imageDataset.length} image(s) with batch size ${batchSize}`,
          'success',
        )

        // Calculate initial rankings before starting training
        trainEpoch()
      })

      // Stop training
      stopBtn.addEventListener('click', () => {
        stopTraining()
      })

      function stopTraining() {
        isTraining = false
        startBtn.disabled = false
        stopBtn.disabled = true
        drawBoxBtn.disabled = imageDataset.length === 0
        batchSizeInput.disabled = false
        temperatureInput.disabled = false
        learningRateInput.disabled = false
        selectionStrategySelect.disabled = false
        statusDiv.textContent = `Training stopped. Processed ${currentEpoch} epochs across ${imageDataset.length} image(s).`
        log('Training stopped', 'info')
      }

      // Drawing mode toggle
      drawBoxBtn.addEventListener('click', () => {
        isDrawingMode = !isDrawingMode
        if (isDrawingMode) {
          drawBoxBtn.textContent = 'Cancel Drawing'
          drawBoxBtn.style.background = '#e74c3c'
          // Enable pointer events on all annotation canvases
          imageDataset.forEach(imgData => {
            if (imgData.canvasElements) {
              imgData.canvasElements.annotCanvas.style.pointerEvents = 'auto'
              imgData.canvasElements.container.classList.add('drawing-mode')
            }
          })
          statusDiv.textContent =
            'Drawing mode: Click on an image to select it, then click and drag to draw target box'
          log('Drawing mode enabled', 'info')
        } else {
          drawBoxBtn.textContent = 'Draw Target Box'
          drawBoxBtn.style.background = '#3498db'
          // Disable pointer events on all annotation canvases
          imageDataset.forEach(imgData => {
            if (imgData.canvasElements) {
              imgData.canvasElements.annotCanvas.style.pointerEvents = 'none'
              imgData.canvasElements.container.classList.remove('drawing-mode')
            }
          })
          // Remove active class from all
          document.querySelectorAll('.image-item').forEach(item => {
            item.classList.remove('active')
          })
          statusDiv.textContent = 'Drawing mode disabled'
          log('Drawing mode disabled', 'info')
        }
      })

      // Mouse event handlers for drawing (attached to canvases when created)
      function attachDrawingHandlers(imgData, index) {
        const { annotCanvas, imageCanvas } = imgData.canvasElements
        const annotCtx = annotCanvas.getContext('2d')

        function getCanvasCoordinates(e) {
          const rect = annotCanvas.getBoundingClientRect()
          const scaleX = annotCanvas.width / rect.width
          const scaleY = annotCanvas.height / rect.height
          return {
            x: (e.clientX - rect.left) * scaleX,
            y: (e.clientY - rect.top) * scaleY,
          }
        }

        annotCanvas.addEventListener('mousedown', e => {
          if (!isDrawingMode || currentImageIndex !== index) return
          isDrawing = true
          const coords = getCanvasCoordinates(e)
          drawStartX = coords.x
          drawStartY = coords.y
        })

        annotCanvas.addEventListener('mousemove', e => {
          if (!isDrawingMode || !isDrawing || currentImageIndex !== index)
            return
          const coords = getCanvasCoordinates(e)

          // Clear and redraw
          annotCtx.clearRect(0, 0, annotCanvas.width, annotCanvas.height)
          drawTargetBoxForImage(index) // Redraw existing target box

          // Draw current selection
          const width = coords.x - drawStartX
          const height = coords.y - drawStartY
          annotCtx.strokeStyle = '#3498db'
          annotCtx.lineWidth = 2
          annotCtx.setLineDash([3, 3])
          annotCtx.strokeRect(drawStartX, drawStartY, width, height)
          annotCtx.setLineDash([])
        })

        annotCanvas.addEventListener('mouseup', e => {
          if (!isDrawingMode || !isDrawing || currentImageIndex !== index)
            return
          isDrawing = false

          const coords = getCanvasCoordinates(e)
          const x1 = Math.min(drawStartX, coords.x)
          const y1 = Math.min(drawStartY, coords.y)
          const x2 = Math.max(drawStartX, coords.x)
          const y2 = Math.max(drawStartY, coords.y)

          const width = x2 - x1
          const height = y2 - y1

          // Only update if box is large enough
          if (width > 10 && height > 10) {
            // Convert to normalized center coordinates
            const centerX = (x1 + width / 2) / imageCanvas.width
            const centerY = (y1 + height / 2) / imageCanvas.height
            const normWidth = width / imageCanvas.width
            const normHeight = height / imageCanvas.height

            // Clamp to [0, 1]
            const clampedCenterX = Math.max(0, Math.min(1, centerX))
            const clampedCenterY = Math.max(0, Math.min(1, centerY))
            const clampedWidth = Math.max(0.01, Math.min(1, normWidth))
            const clampedHeight = Math.max(0.01, Math.min(1, normHeight))

            updateTargetBox(
              clampedCenterX,
              clampedCenterY,
              clampedWidth,
              clampedHeight,
            )

            // Exit drawing mode
            isDrawingMode = false
            drawBoxBtn.textContent = 'Draw Target Box'
            drawBoxBtn.style.background = '#3498db'
            imageDataset.forEach(imgData => {
              if (imgData.canvasElements) {
                imgData.canvasElements.annotCanvas.style.pointerEvents = 'none'
                imgData.canvasElements.container.classList.remove(
                  'drawing-mode',
                )
              }
            })
            document.querySelectorAll('.image-item').forEach(item => {
              item.classList.remove('active')
            })
            statusDiv.textContent =
              'Target box updated. Click "Start Training" to begin.'
          } else {
            annotCtx.clearRect(0, 0, annotCanvas.width, annotCanvas.height)
            drawTargetBoxForImage(index)
          }
        })

        annotCanvas.addEventListener('mouseleave', () => {
          if (isDrawing && currentImageIndex === index) {
            isDrawing = false
            annotCtx.clearRect(0, 0, annotCanvas.width, annotCanvas.height)
            drawTargetBoxForImage(index)
          }
        })
      }

      // Initialize on page load
      window.addEventListener('load', async () => {
        log('Initializing...', 'info')
        // Ensure batch size input is enabled
        batchSizeInput.disabled = false
        initializeModel()

        // Check if Firefox has preserved file selections
        if (imageInput.files && imageInput.files.length > 0) {
          log(
            `Found ${imageInput.files.length} previously selected file(s), loading...`,
            'info',
          )
          // Trigger the change event to load all images
          const event = new Event('change', { bubbles: true })
          imageInput.dispatchEvent(event)
        }
      })
    </script>
  </body>
</html>
