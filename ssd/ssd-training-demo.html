<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>SSD Training Demo - Single Image</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.2.0"></script>
    <style>
      * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
      }

      body {
        font-family:
          -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu,
          Cantarell, sans-serif;
        padding: 20px;
        background: #f5f5f5;
        color: #333;
      }

      .container {
        max-width: 1200px;
        margin: 0 auto;
        background: white;
        padding: 30px;
        border-radius: 12px;
        box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
      }

      h1 {
        margin-bottom: 10px;
        color: #2c3e50;
      }

      .subtitle {
        color: #7f8c8d;
        margin-bottom: 30px;
      }

      .upload-section {
        margin-bottom: 30px;
        padding: 20px;
        background: #f8f9fa;
        border-radius: 8px;
      }

      .file-input-wrapper {
        margin-bottom: 15px;
      }

      input[type='file'] {
        margin-bottom: 10px;
      }

      button {
        background: #3498db;
        color: white;
        border: none;
        padding: 12px 24px;
        border-radius: 6px;
        cursor: pointer;
        font-size: 16px;
        margin-right: 10px;
        transition: background 0.3s;
      }

      button:hover:not(:disabled) {
        background: #2980b9;
      }

      button:disabled {
        background: #bdc3c7;
        cursor: not-allowed;
      }

      .status {
        margin-top: 15px;
        padding: 12px;
        background: #e8f4f8;
        border-left: 4px solid #3498db;
        border-radius: 4px;
      }

      .training-info {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 15px;
        margin-bottom: 30px;
      }

      .info-card {
        background: #f8f9fa;
        padding: 15px;
        border-radius: 8px;
        text-align: center;
      }

      .info-label {
        font-size: 12px;
        color: #7f8c8d;
        text-transform: uppercase;
        margin-bottom: 5px;
      }

      .info-value {
        font-size: 24px;
        font-weight: bold;
        color: #2c3e50;
      }

      .images-grid {
        display: grid;
        grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
        gap: 20px;
        margin-bottom: 20px;
      }

      .canvas-container {
        position: relative;
        display: inline-block;
        border: 2px solid #ddd;
        border-radius: 8px;
        overflow: hidden;
        width: 100%;
      }

      .canvas-container.drawing-mode {
        border-color: #3498db;
        box-shadow: 0 0 10px rgba(52, 152, 219, 0.5);
      }

      .image-item {
        display: flex;
        flex-direction: column;
      }

      .image-item .image-name {
        margin-bottom: 8px;
        font-weight: bold;
        color: #2c3e50;
        font-size: 14px;
        word-wrap: break-word;
        word-break: break-all;
        overflow-wrap: break-word;
        max-width: 100%;
        line-height: 1.4;
      }

      .image-item canvas {
        display: block;
        max-width: 100%;
        height: auto;
      }

      .prediction-overlay {
        position: absolute;
        top: 0;
        left: 0;
        pointer-events: none;
        z-index: 3;
      }

      .annotation-canvas {
        position: absolute;
        top: 0;
        left: 0;
        cursor: crosshair;
        z-index: 2;
        pointer-events: none;
      }

      .image-item.active {
        border: 3px solid #2ecc71;
        border-radius: 8px;
        padding: 5px;
      }

      .prediction-box {
        position: absolute;
        border: 3px solid #e74c3c;
        background: rgba(231, 76, 60, 0.1);
        box-sizing: border-box;
      }

      .prediction-label {
        position: absolute;
        top: -20px;
        left: 0;
        background: #e74c3c;
        color: white;
        padding: 2px 6px;
        font-size: 12px;
        border-radius: 3px;
        white-space: nowrap;
      }

      .log {
        margin-top: 20px;
        padding: 15px;
        background: #2c3e50;
        color: #ecf0f1;
        border-radius: 8px;
        font-family: 'Courier New', monospace;
        font-size: 12px;
        max-height: 200px;
        overflow-y: auto;
      }

      .log-entry {
        margin-bottom: 5px;
      }

      .log-entry.success {
        color: #2ecc71;
      }

      .log-entry.error {
        color: #e74c3c;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>ðŸš€ SSD Training Demo</h1>
      <p class="subtitle">
        Train on multiple images and watch predictions improve over time
      </p>

      <div class="upload-section">
        <div class="file-input-wrapper">
          <label for="imageInput">Select images (multiple):</label>
          <input type="file" id="imageInput" accept="image/*" multiple />
        </div>
        <div style="margin-top: 10px">
          <button id="startTrainingBtn" disabled>Start Training</button>
          <button id="stopTrainingBtn" disabled>Stop Training</button>
          <button id="drawBoxBtn" disabled>Draw Target Box</button>
          <span id="imageCounter" style="margin-left: 10px; padding: 0 10px"
            >0 images loaded</span
          >
        </div>
        <div class="status" id="status">Please select images to begin</div>
      </div>

      <div class="training-info">
        <div class="info-card">
          <div class="info-label">Epoch</div>
          <div class="info-value" id="epochValue">0</div>
        </div>
        <div class="info-card">
          <div class="info-label">Loss</div>
          <div class="info-value" id="lossValue">-</div>
        </div>
        <div class="info-card">
          <div class="info-label">Box Loss</div>
          <div class="info-value" id="boxLossValue">-</div>
        </div>
        <div class="info-card">
          <div class="info-label">Class Loss</div>
          <div class="info-value" id="classLossValue">-</div>
        </div>
      </div>

      <div class="images-grid" id="imagesGrid"></div>

      <div class="log" id="log"></div>
    </div>

    <script>
      // Global variables
      let detectionModel = null
      let featureExtractor = null
      let isTraining = false
      let currentEpoch = 0
      let imageElement = null
      let imageTensor = null
      let targetBox = null // [x, y, w, h] normalized coordinates
      let targetClass = null // one-hot encoded class
      let currentImageFileName = null

      // Multiple images support
      let imageDataset = [] // Array of {file, name, element, tensor, box, class}
      let currentImageIndex = 0
      let currentTrainingImageIndex = 0

      // Drawing state
      let isDrawingMode = false
      let isDrawing = false
      let drawStartX = 0
      let drawStartY = 0

      const IMAGE_SIZE = 224
      const NUM_CLASSES = 2 // background + 1 object class
      const LEARNING_RATE = 1e-4

      // UI elements
      const imageInput = document.getElementById('imageInput')
      const startBtn = document.getElementById('startTrainingBtn')
      const stopBtn = document.getElementById('stopTrainingBtn')
      const drawBoxBtn = document.getElementById('drawBoxBtn')
      const imageCounter = document.getElementById('imageCounter')
      const statusDiv = document.getElementById('status')
      const imagesGrid = document.getElementById('imagesGrid')
      const logDiv = document.getElementById('log')

      // Logging utility
      function log(message, type = 'info') {
        const entry = document.createElement('div')
        entry.className = `log-entry ${type}`
        entry.textContent = `[${new Date().toLocaleTimeString()}] ${message}`
        logDiv.appendChild(entry)
        logDiv.scrollTop = logDiv.scrollHeight
        console.log(message)
      }

      // LocalStorage utilities
      function getStorageKey(fileName) {
        return `ssd_target_box_${fileName}`
      }

      function saveTargetBox(fileName, box) {
        if (!fileName) return
        const key = getStorageKey(fileName)
        localStorage.setItem(key, JSON.stringify(box))
        log(`Target box saved for ${fileName}`, 'success')
      }

      function loadTargetBox(fileName) {
        if (!fileName) return null
        const key = getStorageKey(fileName)
        const saved = localStorage.getItem(key)
        if (saved) {
          try {
            return JSON.parse(saved)
          } catch (e) {
            log(`Error loading saved box: ${e.message}`, 'error')
            return null
          }
        }
        return null
      }

      function clearTargetBox(fileName) {
        if (!fileName) return
        const key = getStorageKey(fileName)
        localStorage.removeItem(key)
        log(`Target box cleared for ${fileName}`, 'info')
      }

      // Update target box tensor from normalized coordinates
      function updateTargetBox(centerX, centerY, width, height) {
        // Update current display
        targetBox = tf.tensor2d([[centerX, centerY, width, height]])

        // Update dataset entry
        if (imageDataset[currentImageIndex]) {
          // Dispose old tensors
          if (imageDataset[currentImageIndex].box) {
            imageDataset[currentImageIndex].box.dispose()
          }

          imageDataset[currentImageIndex].box = targetBox.clone()
          imageDataset[currentImageIndex].centerX = centerX
          imageDataset[currentImageIndex].centerY = centerY
          imageDataset[currentImageIndex].width = width
          imageDataset[currentImageIndex].height = height
        }

        if (currentImageFileName) {
          saveTargetBox(currentImageFileName, {
            centerX,
            centerY,
            width,
            height,
          })
        }
        log(
          `Target box updated: [${centerX.toFixed(2)}, ${centerY.toFixed(2)}, ${width.toFixed(2)}, ${height.toFixed(2)}]`,
          'info',
        )
        drawTargetBoxForImage(currentImageIndex)
      }

      // Draw target box on a specific image's annotation canvas
      function drawTargetBoxForImage(index) {
        if (index < 0 || index >= imageDataset.length) return
        const imgData = imageDataset[index]
        if (!imgData || !imgData.box || !imgData.canvasElements) return

        const { annotCanvas, imageCanvas } = imgData.canvasElements
        const annotCtx = annotCanvas.getContext('2d')

        annotCtx.clearRect(0, 0, annotCanvas.width, annotCanvas.height)

        imgData.box.array().then(data => {
          const box = data[0]
          const centerX = box[0] * imageCanvas.width
          const centerY = box[1] * imageCanvas.height
          const width = box[2] * imageCanvas.width
          const height = box[3] * imageCanvas.height
          const x1 = centerX - width / 2
          const y1 = centerY - height / 2

          // Draw target box
          annotCtx.strokeStyle = '#2ecc71'
          annotCtx.lineWidth = 3
          annotCtx.setLineDash([5, 5])
          annotCtx.strokeRect(x1, y1, width, height)
          annotCtx.setLineDash([])

          // Draw label
          annotCtx.fillStyle = '#2ecc71'
          annotCtx.fillRect(x1, y1 - 25, 150, 25)
          annotCtx.fillStyle = 'white'
          annotCtx.font = '14px Arial'
          annotCtx.fillText('Target Box (Green)', x1 + 5, y1 - 8)
        })
      }

      // Draw target boxes for all images
      function drawAllTargetBoxes() {
        for (let i = 0; i < imageDataset.length; i++) {
          drawTargetBoxForImage(i)
        }
      }

      // Initialize: Load MobileNet feature extractor
      async function initializeModel() {
        log('Loading MobileNet feature extractor...', 'info')
        statusDiv.textContent = 'Loading MobileNet...'

        try {
          // Load MobileNet v3 feature vector model (local)
          // This is a GraphModel that outputs feature vectors directly
          // Path is absolute from web server root
          const modelUrl =
            '/saved_models/mobilenet-v3-tfjs-large-100-224-feature-vector-v1/model.json'

          log(`Loading from: ${modelUrl}`, 'info')
          const mobilenetGraph = await tf.loadGraphModel(modelUrl)

          // GraphModel outputs features directly [batch, 1280]
          // We'll wrap it in a function that can be used in our LayersModel
          // For now, we'll use it directly in buildDetectionModel
          featureExtractor = mobilenetGraph

          log('MobileNet loaded successfully (GraphModel)', 'success')
          log('Feature vector size: 1280', 'info')

          // Build detection model
          buildDetectionModel()
        } catch (error) {
          log(`Error loading model: ${error.message}`, 'error')
          statusDiv.textContent = `Error: ${error.message}`
          log('Trying alternative model path...', 'info')

          // Fallback: try classification model
          try {
            const altModelUrl =
              '/saved_models/mobilenet-v3-tfjs-large-100-224-classification-v1/model.json'
            log(`Trying: ${altModelUrl}`, 'info')
            const mobilenetGraph = await tf.loadGraphModel(altModelUrl)

            // For classification model, we need to extract features before the classification layer
            // GraphModels don't have layers, so we'll use it as-is and handle in buildDetectionModel
            featureExtractor = mobilenetGraph
            log(
              'MobileNet loaded successfully (fallback, classification model)',
              'success',
            )
            buildDetectionModel()
          } catch (fallbackError) {
            log(`Fallback also failed: ${fallbackError.message}`, 'error')
            statusDiv.textContent = `Error: ${fallbackError.message}. Make sure the model files are in saved_models/ directory.`
          }
        }
      }

      // Build SSD detection head
      function buildDetectionModel() {
        log('Building detection model...', 'info')

        // Check if featureExtractor is a GraphModel
        const isGraphModel = featureExtractor && 'execute' in featureExtractor

        if (isGraphModel) {
          // For GraphModel, build a simple detection head that takes features as input
          // Features will be extracted separately in the training loop
          const featureInput = tf.input({ shape: [1280] }) // Feature vector size

          // Bounding box head
          const boxHead = tf.layers
            .dense({
              units: 4,
              activation: 'sigmoid',
              name: 'box_head',
            })
            .apply(featureInput)

          // Classification head
          const classHead = tf.layers
            .dense({
              units: NUM_CLASSES,
              activation: 'softmax',
              name: 'class_head',
            })
            .apply(featureInput)

          detectionModel = tf.model({
            inputs: featureInput,
            outputs: [boxHead, classHead],
          })
        } else {
          // For LayersModel, use the original approach
          const input = tf.input({ shape: [IMAGE_SIZE, IMAGE_SIZE, 3] })
          const features = featureExtractor.apply(input)

          // Flatten if needed
          const flattened = tf.layers.flatten().apply(features)

          // Bounding box head
          const boxHead = tf.layers
            .dense({
              units: 4,
              activation: 'sigmoid',
              name: 'box_head',
            })
            .apply(flattened)

          // Classification head
          const classHead = tf.layers
            .dense({
              units: NUM_CLASSES,
              activation: 'softmax',
              name: 'class_head',
            })
            .apply(flattened)

          detectionModel = tf.model({
            inputs: input,
            outputs: [boxHead, classHead],
          })
        }

        // Compile model
        const optimizer = tf.train.adam(LEARNING_RATE)
        detectionModel.compile({
          optimizer: optimizer,
          loss: ['meanSquaredError', 'categoricalCrossentropy'],
          lossWeights: [1.0, 0.5], // Weight box loss more
          metrics: ['accuracy'],
        })

        log('Detection model built and compiled', 'success')
        log(`Model summary: ${detectionModel.countParams()} parameters`, 'info')
      }

      // Load a single image into dataset
      function loadImageIntoDataset(file, index) {
        return new Promise((resolve, reject) => {
          const reader = new FileReader()
          reader.onload = async event => {
            const img = new Image()
            img.onload = async () => {
              // Preprocess image for model
              const tensor = tf.browser
                .fromPixels(img)
                .resizeNearestNeighbor([IMAGE_SIZE, IMAGE_SIZE])
                .toFloat()
                .div(127.5)
                .sub(1.0)
                .expandDims(0)

              // Load saved target box or use default
              const savedBox = loadTargetBox(file.name)
              let centerX, centerY, width, height

              if (savedBox) {
                centerX = savedBox.centerX
                centerY = savedBox.centerY
                width = savedBox.width
                height = savedBox.height
              } else {
                centerX = 0.5
                centerY = 0.5
                width = 0.4
                height = 0.4
              }

              const box = tf.tensor2d([[centerX, centerY, width, height]])
              const cls = tf.tensor2d([[0, 1]])

              imageDataset[index] = {
                file,
                name: file.name,
                element: img,
                tensor,
                box,
                class: cls,
                centerX,
                centerY,
                width,
                height,
              }

              resolve()
            }
            img.onerror = reject
            img.src = event.target.result
          }
          reader.onerror = reject
          reader.readAsDataURL(file)
        })
      }

      // Display all images in grid
      function displayAllImages() {
        if (imageDataset.length === 0) {
          imagesGrid.innerHTML = ''
          return
        }

        imagesGrid.innerHTML = ''

        imageDataset.forEach((imgData, index) => {
          // Create container for this image
          const imageItem = document.createElement('div')
          imageItem.className = 'image-item'
          imageItem.dataset.index = index

          // Image name
          const nameDiv = document.createElement('div')
          nameDiv.className = 'image-name'
          nameDiv.textContent = imgData.name
          imageItem.appendChild(nameDiv)

          // Canvas container
          const canvasContainer = document.createElement('div')
          canvasContainer.className = 'canvas-container'
          canvasContainer.dataset.index = index

          // Create canvases
          const imageCanvas = document.createElement('canvas')
          const annotCanvas = document.createElement('canvas')
          annotCanvas.className = 'annotation-canvas'
          const predCanvas = document.createElement('canvas')
          predCanvas.className = 'prediction-overlay'

          // Set canvas sizes
          imageCanvas.width = imgData.element.width
          imageCanvas.height = imgData.element.height
          annotCanvas.width = imgData.element.width
          annotCanvas.height = imgData.element.height
          predCanvas.width = imgData.element.width
          predCanvas.height = imgData.element.height

          // Draw image
          const ctx = imageCanvas.getContext('2d')
          ctx.drawImage(imgData.element, 0, 0)

          // Store canvas references
          imgData.canvasElements = {
            imageCanvas,
            annotCanvas,
            predCanvas,
            container: canvasContainer,
            item: imageItem,
          }

          canvasContainer.appendChild(imageCanvas)
          canvasContainer.appendChild(annotCanvas)
          canvasContainer.appendChild(predCanvas)
          imageItem.appendChild(canvasContainer)

          // Click handler to select image for drawing
          canvasContainer.addEventListener('click', () => {
            if (isDrawingMode) {
              // Remove active class from all
              document.querySelectorAll('.image-item').forEach(item => {
                item.classList.remove('active')
              })
              // Add active class to clicked image
              imageItem.classList.add('active')
              currentImageIndex = index
              currentImageFileName = imgData.name
              imageElement = imgData.element
              imageTensor = imgData.tensor
              targetBox = imgData.box
              targetClass = imgData.class
              log(
                `Selected image ${index + 1}: ${imgData.name} for drawing`,
                'info',
              )
            }
          })

          // Attach drawing handlers to this image's canvas
          attachDrawingHandlers(imgData, index)

          imagesGrid.appendChild(imageItem)
        })

        // Draw target boxes for all images
        drawAllTargetBoxes()

        // Update UI
        imageCounter.textContent = `${imageDataset.length} image(s) loaded`
        statusDiv.textContent = `${imageDataset.length} image(s) loaded. Click "Draw Target Box" then click on an image to annotate it.`
        startBtn.disabled = false
        drawBoxBtn.disabled = false

        // Set first image as active if drawing mode
        if (isDrawingMode && imageDataset.length > 0) {
          currentImageIndex = 0
          const firstItem = imageDataset[0].canvasElements?.item
          if (firstItem) {
            firstItem.classList.add('active')
            currentImageFileName = imageDataset[0].name
            imageElement = imageDataset[0].element
            imageTensor = imageDataset[0].tensor
            targetBox = imageDataset[0].box
            targetClass = imageDataset[0].class
          }
        }
      }

      // Handle multiple image selection
      imageInput.addEventListener('change', async e => {
        const files = Array.from(e.target.files)
        if (files.length === 0) return

        log(`Loading ${files.length} image(s)...`, 'info')
        statusDiv.textContent = `Loading ${files.length} image(s)...`

        // Clear previous dataset
        imageDataset.forEach(item => {
          if (item.tensor) item.tensor.dispose()
          if (item.box) item.box.dispose()
          if (item.class) item.class.dispose()
        })
        imageDataset = []

        // Load all images
        try {
          for (let i = 0; i < files.length; i++) {
            await loadImageIntoDataset(files[i], i)
            log(`Loaded ${i + 1}/${files.length}: ${files[i].name}`, 'success')
          }

          currentImageIndex = 0
          displayAllImages()

          log(`All ${files.length} images loaded successfully`, 'success')
        } catch (error) {
          log(`Error loading images: ${error.message}`, 'error')
          statusDiv.textContent = `Error: ${error.message}`
        }
      })

      // Training loop - cycles through all images
      async function trainEpoch() {
        if (!isTraining || !detectionModel || imageDataset.length === 0) return

        try {
          // Get current training image (cycle through dataset)
          const imgData = imageDataset[currentTrainingImageIndex]
          const trainTensor = imgData.tensor
          const trainBox = imgData.box
          const trainClass = imgData.class

          const isGraphModel = featureExtractor && 'execute' in featureExtractor
          let xs, ys

          if (isGraphModel) {
            // Extract features using GraphModel (frozen, no gradients)
            const features = featureExtractor.execute(
              { 'inputs:0': trainTensor },
              'Identity:0',
            )
            xs = features
            ys = [trainBox, trainClass]
          } else {
            // For LayersModel, use image directly
            xs = trainTensor
            ys = [trainBox, trainClass]
          }

          // Train for one epoch (1 batch)
          const history = await detectionModel.fit(xs, ys, {
            epochs: 1,
            batchSize: 1,
            verbose: 0,
          })

          currentEpoch++

          // Update UI
          document.getElementById('epochValue').textContent = currentEpoch

          const boxLoss = history.history.loss[0]
          const classLoss = history.history.loss[1] || 0
          const totalLoss = boxLoss + classLoss

          document.getElementById('lossValue').textContent =
            totalLoss.toFixed(4)
          document.getElementById('boxLossValue').textContent =
            boxLoss.toFixed(4)
          document.getElementById('classLossValue').textContent =
            classLoss.toFixed(4)

          // Update status to show which image is being trained
          statusDiv.textContent = `Training on image ${currentTrainingImageIndex + 1}/${imageDataset.length}: ${imgData.name} (Epoch: ${currentEpoch})`

          // Cleanup if GraphModel (features tensor)
          if (isGraphModel && xs !== trainTensor) {
            xs.dispose()
          }

          // Move to next image for next epoch
          currentTrainingImageIndex =
            (currentTrainingImageIndex + 1) % imageDataset.length

          // Run inference and visualize on all images
          await visualizePredictions()

          // Continue training - no delay needed since we cycle through multiple images
          if (isTraining) {
            trainEpoch()
          }
        } catch (error) {
          log(`Training error: ${error.message}`, 'error')
          stopTraining()
        }
      }

      // Visualize predictions on all images
      async function visualizePredictions() {
        if (!detectionModel || imageDataset.length === 0) return

        try {
          const isGraphModel = featureExtractor && 'execute' in featureExtractor

          // Visualize predictions for all images
          for (let i = 0; i < imageDataset.length; i++) {
            const imgData = imageDataset[i]
            if (!imgData.canvasElements) continue

            const { predCanvas, imageCanvas } = imgData.canvasElements
            const predCtx = predCanvas.getContext('2d')

            let modelInput
            if (isGraphModel) {
              const features = featureExtractor.execute(
                { 'inputs:0': imgData.tensor },
                'Identity:0',
              )
              modelInput = features
            } else {
              modelInput = imgData.tensor
            }

            const [predBoxes, predClasses] = detectionModel.predict(modelInput)

            // Cleanup if GraphModel
            if (isGraphModel && modelInput !== imgData.tensor) {
              modelInput.dispose()
            }

            // Get values
            const boxData = await predBoxes.data()
            const classData = await predClasses.data()

            // Clear previous predictions
            predCtx.clearRect(0, 0, predCanvas.width, predCanvas.height)

            // Draw predicted bounding box
            const x = boxData[0] * imageCanvas.width
            const y = boxData[1] * imageCanvas.height
            const w = boxData[2] * imageCanvas.width
            const h = boxData[3] * imageCanvas.height

            // Convert center coordinates to top-left
            const x1 = x - w / 2
            const y1 = y - h / 2

            // Draw box
            predCtx.strokeStyle = '#e74c3c'
            predCtx.lineWidth = 3
            predCtx.strokeRect(x1, y1, w, h)

            // Draw label
            const confidence = classData[1] // Object class probability
            predCtx.fillStyle = '#e74c3c'
            predCtx.fillRect(x1, y1 - 20, 100, 20)
            predCtx.fillStyle = 'white'
            predCtx.font = '12px Arial'
            predCtx.fillText(
              `Object: ${(confidence * 100).toFixed(1)}%`,
              x1 + 5,
              y1 - 5,
            )

            // Cleanup
            predBoxes.dispose()
            predClasses.dispose()
          }
        } catch (error) {
          log(`Visualization error: ${error.message}`, 'error')
        }
      }

      // Start training
      startBtn.addEventListener('click', () => {
        if (!detectionModel || imageDataset.length === 0) {
          log('Please load images first', 'error')
          return
        }

        isTraining = true
        currentEpoch = 0
        currentTrainingImageIndex = 0
        startBtn.disabled = true
        stopBtn.disabled = false
        drawBoxBtn.disabled = true
        statusDiv.textContent = `Training started on ${imageDataset.length} image(s)...`
        log(`Training started on ${imageDataset.length} image(s)`, 'success')

        trainEpoch()
      })

      // Stop training
      stopBtn.addEventListener('click', () => {
        stopTraining()
      })

      function stopTraining() {
        isTraining = false
        startBtn.disabled = false
        stopBtn.disabled = true
        drawBoxBtn.disabled = imageDataset.length === 0
        statusDiv.textContent = `Training stopped. Processed ${currentEpoch} epochs across ${imageDataset.length} image(s).`
        log('Training stopped', 'info')
      }

      // Drawing mode toggle
      drawBoxBtn.addEventListener('click', () => {
        isDrawingMode = !isDrawingMode
        if (isDrawingMode) {
          drawBoxBtn.textContent = 'Cancel Drawing'
          drawBoxBtn.style.background = '#e74c3c'
          // Enable pointer events on all annotation canvases
          imageDataset.forEach(imgData => {
            if (imgData.canvasElements) {
              imgData.canvasElements.annotCanvas.style.pointerEvents = 'auto'
              imgData.canvasElements.container.classList.add('drawing-mode')
            }
          })
          statusDiv.textContent =
            'Drawing mode: Click on an image to select it, then click and drag to draw target box'
          log('Drawing mode enabled', 'info')
        } else {
          drawBoxBtn.textContent = 'Draw Target Box'
          drawBoxBtn.style.background = '#3498db'
          // Disable pointer events on all annotation canvases
          imageDataset.forEach(imgData => {
            if (imgData.canvasElements) {
              imgData.canvasElements.annotCanvas.style.pointerEvents = 'none'
              imgData.canvasElements.container.classList.remove('drawing-mode')
            }
          })
          // Remove active class from all
          document.querySelectorAll('.image-item').forEach(item => {
            item.classList.remove('active')
          })
          statusDiv.textContent = 'Drawing mode disabled'
          log('Drawing mode disabled', 'info')
        }
      })

      // Mouse event handlers for drawing (attached to canvases when created)
      function attachDrawingHandlers(imgData, index) {
        const { annotCanvas, imageCanvas } = imgData.canvasElements
        const annotCtx = annotCanvas.getContext('2d')

        function getCanvasCoordinates(e) {
          const rect = annotCanvas.getBoundingClientRect()
          const scaleX = annotCanvas.width / rect.width
          const scaleY = annotCanvas.height / rect.height
          return {
            x: (e.clientX - rect.left) * scaleX,
            y: (e.clientY - rect.top) * scaleY,
          }
        }

        annotCanvas.addEventListener('mousedown', e => {
          if (!isDrawingMode || currentImageIndex !== index) return
          isDrawing = true
          const coords = getCanvasCoordinates(e)
          drawStartX = coords.x
          drawStartY = coords.y
        })

        annotCanvas.addEventListener('mousemove', e => {
          if (!isDrawingMode || !isDrawing || currentImageIndex !== index)
            return
          const coords = getCanvasCoordinates(e)

          // Clear and redraw
          annotCtx.clearRect(0, 0, annotCanvas.width, annotCanvas.height)
          drawTargetBoxForImage(index) // Redraw existing target box

          // Draw current selection
          const width = coords.x - drawStartX
          const height = coords.y - drawStartY
          annotCtx.strokeStyle = '#3498db'
          annotCtx.lineWidth = 2
          annotCtx.setLineDash([3, 3])
          annotCtx.strokeRect(drawStartX, drawStartY, width, height)
          annotCtx.setLineDash([])
        })

        annotCanvas.addEventListener('mouseup', e => {
          if (!isDrawingMode || !isDrawing || currentImageIndex !== index)
            return
          isDrawing = false

          const coords = getCanvasCoordinates(e)
          const x1 = Math.min(drawStartX, coords.x)
          const y1 = Math.min(drawStartY, coords.y)
          const x2 = Math.max(drawStartX, coords.x)
          const y2 = Math.max(drawStartY, coords.y)

          const width = x2 - x1
          const height = y2 - y1

          // Only update if box is large enough
          if (width > 10 && height > 10) {
            // Convert to normalized center coordinates
            const centerX = (x1 + width / 2) / imageCanvas.width
            const centerY = (y1 + height / 2) / imageCanvas.height
            const normWidth = width / imageCanvas.width
            const normHeight = height / imageCanvas.height

            // Clamp to [0, 1]
            const clampedCenterX = Math.max(0, Math.min(1, centerX))
            const clampedCenterY = Math.max(0, Math.min(1, centerY))
            const clampedWidth = Math.max(0.01, Math.min(1, normWidth))
            const clampedHeight = Math.max(0.01, Math.min(1, normHeight))

            updateTargetBox(
              clampedCenterX,
              clampedCenterY,
              clampedWidth,
              clampedHeight,
            )

            // Exit drawing mode
            isDrawingMode = false
            drawBoxBtn.textContent = 'Draw Target Box'
            drawBoxBtn.style.background = '#3498db'
            imageDataset.forEach(imgData => {
              if (imgData.canvasElements) {
                imgData.canvasElements.annotCanvas.style.pointerEvents = 'none'
                imgData.canvasElements.container.classList.remove(
                  'drawing-mode',
                )
              }
            })
            document.querySelectorAll('.image-item').forEach(item => {
              item.classList.remove('active')
            })
            statusDiv.textContent =
              'Target box updated. Click "Start Training" to begin.'
          } else {
            annotCtx.clearRect(0, 0, annotCanvas.width, annotCanvas.height)
            drawTargetBoxForImage(index)
          }
        })

        annotCanvas.addEventListener('mouseleave', () => {
          if (isDrawing && currentImageIndex === index) {
            isDrawing = false
            annotCtx.clearRect(0, 0, annotCanvas.width, annotCanvas.height)
            drawTargetBoxForImage(index)
          }
        })
      }

      // Initialize on page load
      window.addEventListener('load', async () => {
        log('Initializing...', 'info')
        initializeModel()

        // Check if Firefox has preserved file selections
        if (imageInput.files && imageInput.files.length > 0) {
          log(
            `Found ${imageInput.files.length} previously selected file(s), loading...`,
            'info',
          )
          // Trigger the change event to load all images
          const event = new Event('change', { bubbles: true })
          imageInput.dispatchEvent(event)
        }
      })
    </script>
  </body>
</html>
